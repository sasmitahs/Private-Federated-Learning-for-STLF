{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c26839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/flower/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57bad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_weights(weights_list):\n",
    "#     \"\"\"Averages model weights provided as a list of get_weights outputs.\"\"\"\n",
    "#     avg_weights = []\n",
    "#     num_models = len(weights_list)\n",
    "#     for layer_weights in zip(*weights_list):\n",
    "#         avg_layer = np.mean(np.array(layer_weights), axis=0)\n",
    "#         avg_weights.append(avg_layer)\n",
    "#     return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf3f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"train_final.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5334f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>air_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>72.221012</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>39.611586</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593146</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>1.920567</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593147</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>111.532464</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593148</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>456.734799</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter           timestamp  meter_reading primary_use  \\\n",
       "7593144            0      0 2016-05-21 01:00:00      72.221012   Education   \n",
       "7593145            1      0 2016-05-21 01:00:00      39.611586   Education   \n",
       "7593146            2      0 2016-05-21 01:00:00       1.920567   Education   \n",
       "7593147            3      0 2016-05-21 01:00:00     111.532464   Education   \n",
       "7593148            4      0 2016-05-21 01:00:00     456.734799   Education   \n",
       "\n",
       "         air_temperature  \n",
       "7593144             25.6  \n",
       "7593145             25.6  \n",
       "7593146             25.6  \n",
       "7593147             25.6  \n",
       "7593148             25.6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1317d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11712248 entries, 7593144 to 20216099\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   building_id      int64         \n",
      " 1   meter            int64         \n",
      " 2   timestamp        datetime64[ns]\n",
      " 3   meter_reading    float64       \n",
      " 4   primary_use      object        \n",
      " 5   air_temperature  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(1)\n",
      "memory usage: 625.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c5872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_buildings_top3_primary_use(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Clusters building_ids by top 3 primary_use categories.\n",
    "    Remaining categories are grouped into 'Other'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'building_id' and 'primary_use'.\n",
    "\n",
    "    Returns:\n",
    "        dict: {'cluster_0': [...], 'cluster_1': [...], 'cluster_2': [...], 'other': [...]}\n",
    "    \"\"\"\n",
    "    # Step 1: Get top 3 most common primary_use values\n",
    "    top3_uses = df['primary_use'].value_counts().nlargest(3).index.tolist()\n",
    "\n",
    "    # Step 2: Create a mapping of cluster name -> list of building_ids\n",
    "    clusters = defaultdict(list)\n",
    "\n",
    "    # Drop duplicate building_id-primary_use pairs to avoid counting duplicates\n",
    "    unique_buildings = df[['building_id', 'primary_use']].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_buildings.iterrows():\n",
    "        bldg_id = row['building_id']\n",
    "        use = row['primary_use']\n",
    "        if use == top3_uses[0]:\n",
    "            clusters['cluster_0'].append(bldg_id)\n",
    "        elif use == top3_uses[1]:\n",
    "            clusters['cluster_1'].append(bldg_id)\n",
    "        elif use == top3_uses[2]:\n",
    "            clusters['cluster_2'].append(bldg_id)\n",
    "        else:\n",
    "            clusters['other'].append(bldg_id)\n",
    "\n",
    "    return dict(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78746fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_uses = df['primary_use'].value_counts().nlargest(3).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4a1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Education', 'Office', 'Entertainment/public assembly']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68425f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_0: 537 buildings [0, 1, 2, 3, 4]...\n",
      "other: 428 buildings [6, 12, 27, 33, 34]...\n",
      "cluster_1: 269 buildings [9, 15, 17, 19, 21]...\n",
      "cluster_2: 179 buildings [10, 59, 87, 88, 40]...\n"
     ]
    }
   ],
   "source": [
    "clusters = cluster_buildings_top3_primary_use(df)\n",
    "\n",
    "for name, ids in clusters.items():\n",
    "    print(f\"{name}: {len(ids)} buildings {ids[:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac19a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cae38",
   "metadata": {},
   "source": [
    "### Naive Model :\n",
    "Returns values by lag-24 hr (Acts as Lower Bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09974375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa118e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace5d718",
   "metadata": {},
   "source": [
    "### Global Models\n",
    "All data, no Fedeerated Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d88d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1133f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 1410/1410 [10:34<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_global_model.pt\n",
      "Starting experiment with model: gru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 1410/1410 [10:28<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_global_model.pt\n",
      "Starting experiment with model: moe_lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 1410/1410 [12:42<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_global_model.pt\n",
      "Starting experiment with model: moe_gru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 1410/1410 [12:38<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_gru/moe_gru_global_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "\n",
    "    sampled_clients = list(range(NUM_CLIENTS))\n",
    "    \n",
    "\n",
    "    for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "        \n",
    "        train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "        updated_weights, fin_loss = train_model(\n",
    "            global_model, train_loader,\n",
    "            device=DEVICE,\n",
    "            learning_rate=LR,\n",
    "            loss_fn=None,\n",
    "            optimizer_class=optim.Adam,\n",
    "            epochs=LOCAL_EPOCHS\n",
    "        )\n",
    "    checkpoint_path = os.path.join(model_dir, f\"{model_name}_global_model.pt\")\n",
    "    torch.save(global_model.state_dict(), checkpoint_path)\n",
    "    print(f\"Saved global model to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f657d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c146ddbf",
   "metadata": {},
   "source": [
    "## Federated Learning Without Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1f443db",
   "metadata": {},
   "source": [
    "### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed70787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86f325",
   "metadata": {},
   "source": [
    "### FedAvgM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:35<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_fedAvgM.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_fedAvgM.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:36<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_fedAvgM.pt\n",
      "Round 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:35<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_fedAvgM.pt\n",
      "Round 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:36<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_5_fedAvgM.pt\n",
      "Round 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_6_fedAvgM.pt\n",
      "Round 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:35<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_7_fedAvgM.pt\n",
      "Round 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:35<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_8_fedAvgM.pt\n",
      "Round 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:35<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_9_fedAvgM.pt\n",
      "Round 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_10_fedAvgM.pt\n",
      "Starting experiment with model: gru\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:34<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_1_fedAvgM.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:34<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_2_fedAvgM.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:37<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_3_fedAvgM.pt\n",
      "Round 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:34<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_4_fedAvgM.pt\n",
      "Round 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:34<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_5_fedAvgM.pt\n",
      "Round 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:41<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_6_fedAvgM.pt\n",
      "Round 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:46<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_7_fedAvgM.pt\n",
      "Round 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:46<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_8_fedAvgM.pt\n",
      "Round 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:47<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_9_fedAvgM.pt\n",
      "Round 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [01:49<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_10_fedAvgM.pt\n",
      "Starting experiment with model: moe_lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:21<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_1_fedAvgM.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:22<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_2_fedAvgM.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:24<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_3_fedAvgM.pt\n",
      "Round 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:25<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_4_fedAvgM.pt\n",
      "Round 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:24<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_5_fedAvgM.pt\n",
      "Round 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:23<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_6_fedAvgM.pt\n",
      "Round 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:25<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_7_fedAvgM.pt\n",
      "Round 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:23<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_8_fedAvgM.pt\n",
      "Round 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:26<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_9_fedAvgM.pt\n",
      "Round 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:24<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_lstm/moe_lstm_round_10_fedAvgM.pt\n",
      "Starting experiment with model: moe_gru\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:26<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_gru/moe_gru_round_1_fedAvgM.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [02:25<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/moe_gru/moe_gru_round_2_fedAvgM.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  10%|▉         | 21/211 [00:14<02:00,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    velocity = [np.zeros_like(w) for w in global_weights]\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights, velocity = fedavgm_update(global_weights,local_weights,velocity)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvgM.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3a9cc",
   "metadata": {},
   "source": [
    "### FedAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab9adb",
   "metadata": {},
   "source": [
    "### Kuramoto FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1491d6",
   "metadata": {},
   "source": [
    "### Kuramoto-Norm FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_norm(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_norm.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2eafa2",
   "metadata": {},
   "source": [
    "### Kuramoto-Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81244573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_softmax(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_sft.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1244302",
   "metadata": {},
   "source": [
    "### DiffAware FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50779f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "855a8f76",
   "metadata": {},
   "source": [
    "## Federated Learning With Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "CLUSTERS = cluster_buildings_top3_primary_use(df)\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    for cluster_name in CLUSTERS:\n",
    "        os.makedirs(os.path.join(\"results\", model_name, cluster_name), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d800b8",
   "metadata": {},
   "source": [
    "### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d444ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = average_weights(local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44615ff3",
   "metadata": {},
   "source": [
    "### FedAvgM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c531a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights and velocity\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "    cluster_velocities = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        weights = get_weights(model)\n",
    "        velocity = [np.zeros_like(w) for w in weights]\n",
    "\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = weights\n",
    "        cluster_velocities[cluster_name] = velocity\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\nRound {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # ---- FedAvgM Aggregation ----\n",
    "            new_weights, new_velocity = fedavgm_update(\n",
    "                cluster_weights[cluster_name],\n",
    "                local_weights,\n",
    "                cluster_velocities[cluster_name]\n",
    "            )\n",
    "\n",
    "            # Update model, weights, and velocity\n",
    "            set_weights(cluster_models[cluster_name], new_weights)\n",
    "            cluster_weights[cluster_name] = new_weights\n",
    "            cluster_velocities[cluster_name] = new_velocity\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_dir = os.path.join(\"results\", model_name, cluster_name)\n",
    "            os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            ckpt_path = os.path.join(ckpt_dir, f\"{model_name}_{cluster_name}_round_{rnd+1}_fedAvgM.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17ad77",
   "metadata": {},
   "source": [
    "### FedAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a421264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = average_weights(local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219366a",
   "metadata": {},
   "source": [
    "### Kuramoto FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = sync_aggregate(updated_cluster_weights,local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}_kr.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfdd93",
   "metadata": {},
   "source": [
    "### Kuramoto Softmax FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = sync_aggregate_softmax(updated_cluster_weights,local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}_kr_softmax.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8d984",
   "metadata": {},
   "source": [
    "### Kuramoto Norm FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da54ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = sync_aggregate_softmax(updated_cluster_weights,local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}_kr_norm.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad6e28",
   "metadata": {},
   "source": [
    "### Clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments for model: lstm\n",
      "\\Round 1/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_1.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:28<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_1.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:17<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_1.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_1.pt\n",
      "\\Round 2/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:35<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_2.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:28<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_2.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_2.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:12<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_2.pt\n",
      "\\Round 3/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:35<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_3.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:28<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_3.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_3.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_3.pt\n",
      "\\Round 4/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_4.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:29<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_4.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_4.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:12<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_4.pt\n",
      "\\Round 5/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:37<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_5.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:29<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_5.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_5.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_5.pt\n",
      "\\Round 6/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:36<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_6.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:29<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_6.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_6.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_6.pt\n",
      "\\Round 7/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:37<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_7.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:28<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_7.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_7.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_7.pt\n",
      "\\Round 8/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:36<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_8.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:29<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_8.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_8.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_8.pt\n",
      "\\Round 9/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:35<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_9.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:28<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_9.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_9.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:11<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_2/lstm_cluster_2_round_9.pt\n",
      "\\Round 10/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:36<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_0/lstm_cluster_0_round_10.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:29<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/other/lstm_other_round_10.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:18<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/lstm/cluster_1/lstm_cluster_1_round_10.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2:  19%|█▉        | 5/26 [00:02<00:10,  1.94it/s]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a5e2e5e",
   "metadata": {},
   "source": [
    "### FedAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a335fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 150/150 [00:48<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_fedAvg.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 150/150 [00:47<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_fedAvg.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 150/150 [00:48<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_fedAvg.pt\n",
      "Round 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 150/150 [00:48<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_fedAvg.pt\n",
      "Round 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 150/150 [00:47<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_5_fedAvg.pt\n",
      "Round 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  97%|█████████▋| 145/150 [00:46<00:01,  2.96it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e44db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a8a8d1",
   "metadata": {},
   "source": [
    "### FedAvgM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6693f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 15/15 [00:42<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results\\lstm\\lstm_round_1_kr_norm.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  40%|████      | 6/15 [00:20<00:30,  3.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     set_weights(local_model, global_weights)\n\u001b[0;32m     35\u001b[0m     train_loader, test_loader \u001b[38;5;241m=\u001b[39m load_energy_data_feather(cid, filepath\u001b[38;5;241m=\u001b[39mDATA_FILE)\n\u001b[1;32m---> 37\u001b[0m     updated_weights, fin_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_EPOCHS\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Federated averaging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\my_utils.py:103\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, device, learning_rate, loss_fn, optimizer_class, epochs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    102\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 103\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y_batch)\n\u001b[0;32m    105\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\Models.py:136\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# x: shape (batch, time, input_features)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m            \u001b[38;5;66;03m# out: (batch, time, hidden_size)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]              \u001b[38;5;66;03m# Take last time step output: (batch, hidden_size)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)               \u001b[38;5;66;03m# Final output: (batch, output_size)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    velocity = [np.zeros_like(w) for w in global_weights]\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights, velocity = fedavgm_update(global_weights,local_weights,velocity)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvgM.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9d5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d7749f",
   "metadata": {},
   "source": [
    "### Kuramoto FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e051a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30767af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b81983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_norm(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_norm.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aeb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 10/10 [01:16<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC Weights:[1.1280927881409405e-24, 3.455221414490252e-24, 2.7815943992592906e-10, 1.5342428063772783e-20, 8.519412258989334e-11, 1.0, 4.7079616409486216e-23, 0.0, 0.0, 1.4587423713408043e-08] \n",
      "Saved global model to results\\lstm\\lstm_round_1_kr.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 10/10 [01:16<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC Weights:[0.051666800892013795, 2.0060822225145682e-07, 0.0038842655760772567, 0.33163288880904007, 0.05313184572821639, 0.17136356681197534, 4.1494413146093236e-12, 2.694967957872787e-05, 0.3882710659981862, 2.2412009829798056e-05] \n",
      "Saved global model to results\\lstm\\lstm_round_2_kr.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  30%|███       | 3/10 [00:19<00:46,  6.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     set_weights(local_model, global_weights)\n\u001b[0;32m     33\u001b[0m     train_loader, test_loader \u001b[38;5;241m=\u001b[39m load_energy_data_feather(cid, filepath\u001b[38;5;241m=\u001b[39mDATA_FILE)\n\u001b[1;32m---> 35\u001b[0m     updated_weights, fin_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_EPOCHS\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Federated averaging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\my_utils.py:105\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, device, learning_rate, loss_fn, optimizer_class, epochs)\u001b[0m\n\u001b[0;32m    103\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m    104\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y_batch)\n\u001b[1;32m--> 105\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    108\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_softmax(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_sft.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371dc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef1b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8f050b",
   "metadata": {},
   "source": [
    "### Diff-Aware Fed Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908746a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314b5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd808c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d94ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4d069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25059312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb3980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc2201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a69607",
   "metadata": {},
   "source": [
    "### Diff-Sync FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bac448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29066235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65a8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0e8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b006b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e8cc8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
