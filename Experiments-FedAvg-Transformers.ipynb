{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c26839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model_transformer, load_energy_data_feather_transformer, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"train_final.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5334f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"transformer\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f443db",
   "metadata": {},
   "source": [
    "### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae92e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_transformer(model, train_loader, device=None, learning_rate=0.001, loss_fn=None, optimizer_class=optim.Adam, epochs=50):\n",
    "    \"\"\"Train the model and return the average loss.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    loss_fn = loss_fn or nn.MSELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # if y_batch.dim() == 3 and y_batch.shape[-1] == 1:\n",
    "            #     y_batch = y_batch.squeeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            # loss = loss_fn(output, y_batch)\n",
    "            loss = loss_fn(output.squeeze(-1), y_batch)  # (batch_size, 24)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        loss_history.append(epoch_loss/len(train_loader))\n",
    "\n",
    "    # fin_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    return get_weights(model), loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed70787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather_transformer(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model_transformer(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
