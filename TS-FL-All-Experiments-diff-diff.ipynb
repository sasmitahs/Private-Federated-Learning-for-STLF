{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c26839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf3f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"train_final.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5334f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>air_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>72.221012</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>39.611586</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593146</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>1.920567</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593147</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>111.532464</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593148</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>456.734799</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter           timestamp  meter_reading primary_use  \\\n",
       "7593144            0      0 2016-05-21 01:00:00      72.221012   Education   \n",
       "7593145            1      0 2016-05-21 01:00:00      39.611586   Education   \n",
       "7593146            2      0 2016-05-21 01:00:00       1.920567   Education   \n",
       "7593147            3      0 2016-05-21 01:00:00     111.532464   Education   \n",
       "7593148            4      0 2016-05-21 01:00:00     456.734799   Education   \n",
       "\n",
       "         air_temperature  \n",
       "7593144             25.6  \n",
       "7593145             25.6  \n",
       "7593146             25.6  \n",
       "7593147             25.6  \n",
       "7593148             25.6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1317d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11712248 entries, 7593144 to 20216099\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   building_id      int64         \n",
      " 1   meter            int64         \n",
      " 2   timestamp        datetime64[ns]\n",
      " 3   meter_reading    float64       \n",
      " 4   primary_use      object        \n",
      " 5   air_temperature  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(1)\n",
      "memory usage: 625.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5188c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDifficultyWeight:\n",
    "    def __init__(self, num_clients, accumulate_iters=20):\n",
    "        self.num_clients = num_clients\n",
    "        self.last_loss = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.learn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.unlearn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.ema_difficulty = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.accumulate_iters = accumulate_iters\n",
    "\n",
    "    def update(self, cid: int, loss_history: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Update difficulty based on loss trend for a client.\n",
    "        Expects a list of per-epoch losses.\n",
    "        \"\"\"\n",
    "        current_loss = torch.tensor(loss_history[-1], dtype=torch.float32).to(DEVICE)\n",
    "        previous_loss = self.last_loss[cid]\n",
    "        delta = current_loss - previous_loss\n",
    "        ratio = torch.log((current_loss + 1e-8) / (previous_loss + 1e-8))\n",
    "\n",
    "        learn = torch.where(delta < 0, -delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "        unlearn = torch.where(delta >= 0, delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "\n",
    "        # EMA update\n",
    "        momentum = (self.accumulate_iters - 1) / self.accumulate_iters\n",
    "        self.learn_score[cid] = momentum * self.learn_score[cid] + (1 - momentum) * learn\n",
    "        self.unlearn_score[cid] = momentum * self.unlearn_score[cid] + (1 - momentum) * unlearn\n",
    "\n",
    "        # Difficulty score\n",
    "        diff_ratio = (self.unlearn_score[cid] + 1e-8) / (self.learn_score[cid] + 1e-8)\n",
    "        difficulty = diff_ratio #torch.pow(diff_ratio, 1 / 5)\n",
    "\n",
    "        # Smooth difficulty over rounds\n",
    "        self.ema_difficulty[cid] = momentum * self.ema_difficulty[cid] + (1 - momentum) * difficulty\n",
    "\n",
    "        self.last_loss[cid] = current_loss\n",
    "        return self.ema_difficulty[cid].item()\n",
    "\n",
    "    def get_normalized_weights(self, client_ids: List[int]) -> List[float]:\n",
    "        weights = [self.ema_difficulty[cid].item() for cid in client_ids]\n",
    "        total = sum(weights)\n",
    "        if total == 0:\n",
    "            return [1.0 / len(client_ids)] * len(client_ids)\n",
    "        return [w / total for w in weights]\n",
    "    \n",
    "    def get_sampling_probabilities(self, min_prob=0.05):\n",
    "        difficulty = self.ema_difficulty\n",
    "        inv_difficulty = 1.0 / (difficulty + 1e-6)\n",
    "        inv_difficulty = inv_difficulty / inv_difficulty.sum()\n",
    "        probs = torch.clamp(inv_difficulty, min=min_prob)\n",
    "        return (probs / probs.sum()).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146ddbf",
   "metadata": {},
   "source": [
    "## Federated Learning Without Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1244302",
   "metadata": {},
   "source": [
    "### DiffAware FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f050b",
   "metadata": {},
   "source": [
    "### Diff-Aware Fed Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7314b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_diff-diff.pt\n",
      "Round 2/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_diff-diff.pt\n",
      "Round 3/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_diff-diff.pt\n",
      "Round 4/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_diff-diff.pt\n",
      "Round 5/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_5_diff-diff.pt\n",
      "Round 6/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_6_diff-diff.pt\n",
      "Round 7/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_7_diff-diff.pt\n",
      "Round 8/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_8_diff-diff.pt\n",
      "Round 9/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_9_diff-diff.pt\n",
      "Round 10/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_10_diff-diff.pt\n",
      "Round 11/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_11_diff-diff.pt\n",
      "Round 12/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_12_diff-diff.pt\n",
      "Round 13/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_13_diff-diff.pt\n",
      "Round 14/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_14_diff-diff.pt\n",
      "Round 15/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_15_diff-diff.pt\n",
      "Round 16/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_16_diff-diff.pt\n",
      "Round 17/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_17_diff-diff.pt\n",
      "Round 18/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:36<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_18_diff-diff.pt\n",
      "Round 19/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_19_diff-diff.pt\n",
      "Round 20/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_20_diff-diff.pt\n",
      "Round 21/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_21_diff-diff.pt\n",
      "Round 22/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_22_diff-diff.pt\n",
      "Round 23/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_23_diff-diff.pt\n",
      "Round 24/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_24_diff-diff.pt\n",
      "Round 25/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_25_diff-diff.pt\n",
      "Round 26/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:36<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_26_diff-diff.pt\n",
      "Round 27/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_27_diff-diff.pt\n",
      "Round 28/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_28_diff-diff.pt\n",
      "Round 29/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_29_diff-diff.pt\n",
      "Round 30/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_30_diff-diff.pt\n",
      "Round 31/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_31_diff-diff.pt\n",
      "Round 32/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_32_diff-diff.pt\n",
      "Round 33/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_33_diff-diff.pt\n",
      "Round 34/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_34_diff-diff.pt\n",
      "Round 35/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_35_diff-diff.pt\n",
      "Round 36/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_36_diff-diff.pt\n",
      "Round 37/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_37_diff-diff.pt\n",
      "Round 38/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_38_diff-diff.pt\n",
      "Round 39/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_39_diff-diff.pt\n",
      "Round 40/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_40_diff-diff.pt\n",
      "Round 41/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_41_diff-diff.pt\n",
      "Round 42/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_42_diff-diff.pt\n",
      "Round 43/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_43_diff-diff.pt\n",
      "Round 44/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_44_diff-diff.pt\n",
      "Round 45/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_45_diff-diff.pt\n",
      "Round 46/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_46_diff-diff.pt\n",
      "Round 47/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_47_diff-diff.pt\n",
      "Round 48/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_48_diff-diff.pt\n",
      "Round 49/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_49_diff-diff.pt\n",
      "Round 50/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_50_diff-diff.pt\n",
      "Starting experiment with model: gru\n",
      "Round 1/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_1_diff-diff.pt\n",
      "Round 2/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_2_diff-diff.pt\n",
      "Round 3/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_3_diff-diff.pt\n",
      "Round 4/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_4_diff-diff.pt\n",
      "Round 5/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_5_diff-diff.pt\n",
      "Round 6/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_6_diff-diff.pt\n",
      "Round 7/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_7_diff-diff.pt\n",
      "Round 8/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_8_diff-diff.pt\n",
      "Round 9/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_9_diff-diff.pt\n",
      "Round 10/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_10_diff-diff.pt\n",
      "Round 11/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_11_diff-diff.pt\n",
      "Round 12/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_12_diff-diff.pt\n",
      "Round 13/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_13_diff-diff.pt\n",
      "Round 14/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_14_diff-diff.pt\n",
      "Round 15/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_15_diff-diff.pt\n",
      "Round 16/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_16_diff-diff.pt\n",
      "Round 17/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_17_diff-diff.pt\n",
      "Round 18/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:44<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_18_diff-diff.pt\n",
      "Round 19/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_19_diff-diff.pt\n",
      "Round 20/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_20_diff-diff.pt\n",
      "Round 21/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_21_diff-diff.pt\n",
      "Round 22/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_22_diff-diff.pt\n",
      "Round 23/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_23_diff-diff.pt\n",
      "Round 24/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_24_diff-diff.pt\n",
      "Round 25/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_25_diff-diff.pt\n",
      "Round 26/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_26_diff-diff.pt\n",
      "Round 27/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_27_diff-diff.pt\n",
      "Round 28/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_28_diff-diff.pt\n",
      "Round 29/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_29_diff-diff.pt\n",
      "Round 30/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_30_diff-diff.pt\n",
      "Round 31/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_31_diff-diff.pt\n",
      "Round 32/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_32_diff-diff.pt\n",
      "Round 33/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_33_diff-diff.pt\n",
      "Round 34/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_34_diff-diff.pt\n",
      "Round 35/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_35_diff-diff.pt\n",
      "Round 36/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_36_diff-diff.pt\n",
      "Round 37/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_37_diff-diff.pt\n",
      "Round 38/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_38_diff-diff.pt\n",
      "Round 39/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_39_diff-diff.pt\n",
      "Round 40/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_40_diff-diff.pt\n",
      "Round 41/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_41_diff-diff.pt\n",
      "Round 42/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_42_diff-diff.pt\n",
      "Round 43/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_43_diff-diff.pt\n",
      "Round 44/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_44_diff-diff.pt\n",
      "Round 45/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:41<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_45_diff-diff.pt\n",
      "Round 46/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_46_diff-diff.pt\n",
      "Round 47/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_47_diff-diff.pt\n",
      "Round 48/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:40<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_48_diff-diff.pt\n",
      "Round 49/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:36<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_49_diff-diff.pt\n",
      "Round 50/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:32<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_50_diff-diff.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "difficulty_tracker = TimeSeriesDifficultyWeight(num_clients=NUM_CLIENTS)\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        # === Difficulty-aware sampling ===\n",
    "        sampling_probs = difficulty_tracker.get_sampling_probabilities(min_prob=0.05)\n",
    "        sampled_clients = np.random.choice(\n",
    "            np.arange(NUM_CLIENTS),\n",
    "            size=int(CLIENT_FRAC * NUM_CLIENTS),\n",
    "            replace=False,\n",
    "            p=sampling_probs\n",
    "        )\n",
    "        print(f\"Sampled {len(sampled_clients)} clients\")\n",
    "\n",
    "        local_weights = []\n",
    "        difficulty_scores = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients):\n",
    "            model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(model, global_weights)\n",
    "            train_loader, _ = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "            updated_weights, loss_history = train_model(\n",
    "                model, train_loader,\n",
    "                device=DEVICE, learning_rate=LR,\n",
    "                loss_fn=None, optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "            # Update difficulty\n",
    "            difficulty = difficulty_tracker.update(cid, loss_history)\n",
    "            difficulty_scores.append(difficulty)\n",
    "\n",
    "        # Normalize difficulty scores\n",
    "        normalized_weights = difficulty_tracker.get_normalized_weights(sampled_clients)\n",
    "\n",
    "        # Difficulty-aware weighted aggregation\n",
    "        global_weights = average_weights(local_weights, client_weights=normalized_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_diff-diff.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52084c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_diff_rev.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_diff_rev.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_diff_rev.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [02:47<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_diff_rev.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 31/211 [00:23<02:14,  1.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m model = model_fn(model_name).to(DEVICE)\n\u001b[32m     20\u001b[39m set_weights(model, global_weights)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m train_loader, _ = \u001b[43mload_energy_data_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m updated_weights, loss_history = train_model(\n\u001b[32m     23\u001b[39m     model, train_loader,\n\u001b[32m     24\u001b[39m     device=DEVICE, learning_rate=LR,\n\u001b[32m     25\u001b[39m     loss_fn=\u001b[38;5;28;01mNone\u001b[39;00m, optimizer_class=optim.Adam,\n\u001b[32m     26\u001b[39m     epochs=LOCAL_EPOCHS\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m local_weights.append(updated_weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Priyankan/FL/Diffusion_FL/energy-ts-diffusion/my_utils.py:35\u001b[39m, in \u001b[36mload_energy_data_feather\u001b[39m\u001b[34m(cid, filepath)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_energy_data_feather\u001b[39m(cid, filepath=\u001b[33m\"\u001b[39m\u001b[33mmeter_0_data_cleaned.feather\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load, preprocess, and return train/test dataloaders for a client.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     df = df[df[\u001b[33m'\u001b[39m\u001b[33mbuilding_id\u001b[39m\u001b[33m'\u001b[39m] == cid]\n\u001b[32m     37\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mmeter_reading\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mmeter_reading\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/io/feather_format.py:124\u001b[39m, in \u001b[36mread_feather\u001b[39m\u001b[34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    121\u001b[39m     path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m, storage_options=storage_options, is_text=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    122\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib.no_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_pyarrow_string_dtype():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeather\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     pa_table = feather.read_table(\n\u001b[32m    129\u001b[39m         handles.handle, columns=columns, use_threads=\u001b[38;5;28mbool\u001b[39m(use_threads)\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend == \u001b[33m\"\u001b[39m\u001b[33mnumpy_nullable\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pyarrow/feather.py:226\u001b[39m, in \u001b[36mread_feather\u001b[39m\u001b[34m(source, columns, use_threads, memory_map, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_feather\u001b[39m(source, columns=\u001b[38;5;28;01mNone\u001b[39;00m, use_threads=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    200\u001b[39m                  memory_map=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs):\n\u001b[32m    201\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m    Read a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m    feather.read_table.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m \u001b[33;03m        The contents of the Feather file as a pandas.DataFrame\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m.to_pandas(use_threads=use_threads, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pyarrow/feather.py:256\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, memory_map, use_threads)\u001b[39m\n\u001b[32m    252\u001b[39m reader = _feather.FeatherReader(\n\u001b[32m    253\u001b[39m     source, use_memory_map=memory_map, use_threads=use_threads)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m column_types = [\u001b[38;5;28mtype\u001b[39m(column) \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: t == \u001b[38;5;28mint\u001b[39m, column_types)):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    difficulty_tracker = TimeSeriesDifficultyWeight(num_clients=NUM_CLIENTS,accumulate_iters=20)\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "        difficulty_scores = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients):\n",
    "            model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(model, global_weights)\n",
    "            train_loader, _ = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "            updated_weights, loss_history = train_model(\n",
    "                model, train_loader,\n",
    "                device=DEVICE, learning_rate=LR,\n",
    "                loss_fn=None, optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "            # Update difficulty\n",
    "            difficulty = difficulty_tracker.update(cid, loss_history)\n",
    "            difficulty_scores.append(difficulty)\n",
    "\n",
    "        # Normalize difficulty scores\n",
    "        normalized_weights = difficulty_tracker.get_normalized_weights(1/np.array(sampled_clients))\n",
    "\n",
    "        # Difficulty-aware weighted aggregation\n",
    "        global_weights = average_weights(local_weights, client_weights=normalized_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_diff_rev.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0e8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b006b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e8cc8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
