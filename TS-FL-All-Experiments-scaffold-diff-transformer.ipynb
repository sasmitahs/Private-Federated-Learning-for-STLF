{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c26839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model_transformer, load_energy_data_feather_transformer, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"train_final.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5334f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"transformer\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f443db",
   "metadata": {},
   "source": [
    "### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae92e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_transformer(model, train_loader, device=None, learning_rate=0.001, loss_fn=None, optimizer_class=optim.Adam, epochs=50):\n",
    "    \"\"\"Train the model and return the average loss.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    loss_fn = loss_fn or nn.MSELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # if y_batch.dim() == 3 and y_batch.shape[-1] == 1:\n",
    "            #     y_batch = y_batch.squeeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            # loss = loss_fn(output, y_batch)\n",
    "            loss = loss_fn(output.squeeze(-1), y_batch)  # (batch_size, 24)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        loss_history.append(epoch_loss/len(train_loader))\n",
    "\n",
    "    # fin_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    return get_weights(model), loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed70787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather_transformer(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model_transformer(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f050b",
   "metadata": {},
   "source": [
    "### Diff-Aware Fed Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDifficultyWeight:\n",
    "    def __init__(self, num_clients, accumulate_iters=20):\n",
    "        self.num_clients = num_clients\n",
    "        self.last_loss = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.learn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.unlearn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.ema_difficulty = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.accumulate_iters = accumulate_iters\n",
    "\n",
    "    def update(self, cid: int, loss_history: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Update difficulty based on loss trend for a client.\n",
    "        Expects a list of per-epoch losses.\n",
    "        \"\"\"\n",
    "        current_loss = torch.tensor(loss_history[-1], dtype=torch.float32).to(DEVICE)\n",
    "        previous_loss = self.last_loss[cid]\n",
    "        delta = current_loss - previous_loss\n",
    "        ratio = torch.log((current_loss + 1e-8) / (previous_loss + 1e-8))\n",
    "\n",
    "        learn = torch.where(delta < 0, -delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "        unlearn = torch.where(delta >= 0, delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "\n",
    "        # EMA update\n",
    "        momentum = (self.accumulate_iters - 1) / self.accumulate_iters\n",
    "        self.learn_score[cid] = momentum * self.learn_score[cid] + (1 - momentum) * learn\n",
    "        self.unlearn_score[cid] = momentum * self.unlearn_score[cid] + (1 - momentum) * unlearn\n",
    "\n",
    "        # Difficulty score\n",
    "        diff_ratio = (self.unlearn_score[cid] + 1e-8) / (self.learn_score[cid] + 1e-8)\n",
    "        difficulty = diff_ratio #torch.pow(diff_ratio, 1 / 5)\n",
    "\n",
    "        # Smooth difficulty over rounds\n",
    "        self.ema_difficulty[cid] = momentum * self.ema_difficulty[cid] + (1 - momentum) * difficulty\n",
    "\n",
    "        self.last_loss[cid] = current_loss\n",
    "        return self.ema_difficulty[cid].item()\n",
    "\n",
    "    def get_normalized_weights(self, client_ids: List[int]) -> List[float]:\n",
    "        weights = [self.ema_difficulty[cid].item() for cid in client_ids]\n",
    "        total = sum(weights)\n",
    "        if total == 0:\n",
    "            return [1.0 / len(client_ids)] * len(client_ids)\n",
    "        return [w / total for w in weights]\n",
    "    \n",
    "    def get_sampling_probabilities(self, min_prob=0.05):\n",
    "        difficulty = self.ema_difficulty\n",
    "        inv_difficulty = 1.0 / (difficulty + 1e-6)\n",
    "        inv_difficulty = inv_difficulty / inv_difficulty.sum()\n",
    "        probs = torch.clamp(inv_difficulty, min=min_prob)\n",
    "        return (probs / probs.sum()).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f9164",
   "metadata": {},
   "source": [
    "## SCAFFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_scaffold(\n",
    "    local_model,\n",
    "    train_loader,         # global_model, train_loader\n",
    "    global_weights,    # x\n",
    "    server_c,          # c\n",
    "    client_ci,         # cᵢ\n",
    "    device=DEVICE,\n",
    "    learning_rate= LR,\n",
    "    loss_fn=None,\n",
    "    optimizer_class=optim.Adam,\n",
    "    epochs= LOCAL_EPOCHS  # 50\n",
    "):\n",
    "    \"\"\"Train client with SCAFFOLD correction. Return Δy, Δc, new cᵢ, final weights.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # print(f\"[DEBUG] Training on: {device}\")\n",
    "\n",
    "    \n",
    "    local_model.to(device)\n",
    "    loss_fn = loss_fn or nn.MSELoss()\n",
    "    optimizer = optimizer_class(local_model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    local_model.train()\n",
    "    total_steps = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # if y_batch.dim() == 3 and y_batch.shape[-1] == 1:\n",
    "            #     y_batch = y_batch.squeeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = local_model(X_batch)\n",
    "            loss = loss_fn(output.squeeze(-1), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ✅ SCAFFOLD correction: adjust each param after normal SGD step  # doubt at this step\n",
    "            with torch.no_grad():\n",
    "                for p, sc_np, ci_np in zip(local_model.parameters(), server_c, client_ci):\n",
    "                    sc_tensor = torch.tensor(sc_np, dtype=p.dtype, device=p.device)\n",
    "                    ci_tensor = torch.tensor(ci_np, dtype=p.dtype, device=p.device)\n",
    "                    p -= learning_rate * (sc_tensor - ci_tensor)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total_steps += 1\n",
    "        \n",
    "        loss_history.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    # Compute deltas\n",
    "    local_weights = get_weights(local_model)\n",
    "    delta_y = [lw - gw for lw, gw in zip(local_weights, global_weights)]\n",
    "\n",
    "    # K = total_steps\n",
    "    K = total_steps\n",
    "    new_ci = []\n",
    "    delta_c = []\n",
    "\n",
    "    for gw, lw, ci, sc in zip(global_weights, local_weights, client_ci, server_c):\n",
    "        ci_new = ci - sc + (gw - lw) / (K * learning_rate)\n",
    "        new_ci.append(ci_new)  # doubt can overide new_ci\n",
    "        delta_c.append(ci_new - ci)\n",
    "\n",
    "    return delta_y, delta_c, new_ci, local_weights, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    difficulty_tracker = TimeSeriesDifficultyWeight(num_clients=NUM_CLIENTS)\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    server_c = [np.zeros_like(w) for w in global_weights]\n",
    "    client_cs = {cid: [np.zeros_like(w) for w in global_weights] for cid in range(NUM_CLIENTS)}\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        # === Difficulty-aware sampling ===\n",
    "        sampling_probs = difficulty_tracker.get_sampling_probabilities(min_prob=0.05)\n",
    "        sampled_clients = np.random.choice(\n",
    "            np.arange(NUM_CLIENTS),\n",
    "            size=int(CLIENT_FRAC * NUM_CLIENTS),\n",
    "            replace=False,\n",
    "            p=sampling_probs\n",
    "        )\n",
    "        print(f\"Sampled {len(sampled_clients)} clients\")\n",
    "\n",
    "        local_weight_deltas = []\n",
    "        local_c_deltas = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "\n",
    "            train_loader, _ = load_energy_data_feather_transformer(cid, filepath=DATA_FILE)\n",
    "\n",
    "            delta_y, delta_c, new_ci, local_weights, loss_history = train_model_scaffold(\n",
    "                local_model, train_loader,\n",
    "                global_weights=global_weights,\n",
    "                server_c=server_c,\n",
    "                client_ci=client_cs[cid],\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "\n",
    "            # === Difficulty update ===\n",
    "            difficulty_tracker.update(cid, loss_history)\n",
    "\n",
    "            local_weight_deltas.append(delta_y)\n",
    "            local_c_deltas.append(delta_c)\n",
    "            client_cs[cid] = new_ci\n",
    "\n",
    "        # === Aggregate and update global weights ===\n",
    "        mean_delta_y = average_weights(local_weight_deltas)\n",
    "        global_weights = [gw + mean_delta_y[i] for i, gw in enumerate(global_weights)]\n",
    "\n",
    "        mean_delta_c = average_weights(local_c_deltas)\n",
    "        frac = len(sampled_clients) / NUM_CLIENTS\n",
    "        server_c = [sc + frac * mean_delta_c[i] for i, sc in enumerate(server_c)]\n",
    "\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        ckpt_path = os.path.join(\"results\", model_name, f\"{model_name}_round_{rnd+1}_scaffold_diff.pt\")\n",
    "        torch.save(global_model.state_dict(), ckpt_path)\n",
    "        print(f\"Saved: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0470873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e8cc8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
