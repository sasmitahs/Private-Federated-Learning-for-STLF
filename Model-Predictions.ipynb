{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36c9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n",
    "from energy_ts_diffusion.task import convert_timeseries_to_numpy  # adjust as per your project\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0cda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d54acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, _ = load_energy_data_feather(403, filepath=DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49778510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def rolling_forecast_on_test(cid, model, filepath=\"meter_\"\n",
    "\"\"\n",
    "\"\", input_len=24, output_len=8):\n",
    "    \"\"\"\n",
    "    Perform rolling window forecast on the test data using a trained model and return\n",
    "    unscaled predictions and ground truths with actual timestamps.\n",
    "\n",
    "    Args:\n",
    "        cid (int): Client/building ID.\n",
    "        model (nn.Module): Trained PyTorch model.\n",
    "        filepath (str): Path to the Feather file.\n",
    "        input_len (int): Input sequence length.\n",
    "        output_len (int): Prediction horizon.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[TimeSeries], List[TimeSeries]]: (predictions_ts_list, ground_truth_ts_list)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and filter data\n",
    "    df = pd.read_feather(filepath)\n",
    "    df = df[df['building_id'] == cid]\n",
    "    df['meter_reading'] = df['meter_reading'].fillna(0)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found for building_id {cid}\")\n",
    "\n",
    "    # Create TimeSeries and scale\n",
    "    ts = TimeSeries.from_dataframe(\n",
    "        df,\n",
    "        time_col='timestamp',\n",
    "        value_cols='meter_reading',\n",
    "        fill_missing_dates=True,\n",
    "        freq='h'\n",
    "    )\n",
    "\n",
    "    _, test_series = ts.split_before(0.75)\n",
    "\n",
    "    # Scale\n",
    "    scaler = MinMaxScaler(feature_range=(0.1, 1))\n",
    "    transformer = Scaler(scaler)\n",
    "    test_series_scaled = transformer.fit_transform(test_series)\n",
    "\n",
    "    test_values_scaled = test_series_scaled.values().squeeze()\n",
    "    test_timestamps = test_series_scaled.time_index\n",
    "\n",
    "    predictions_ts_list = []\n",
    "    ground_truth_ts_list = []\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for i in range(0, len(test_values_scaled) - input_len - output_len + 1):\n",
    "        input_seq = test_values_scaled[i:i+input_len]\n",
    "        true_output = test_values_scaled[i+input_len:i+input_len+output_len]\n",
    "        true_time = test_timestamps[i+input_len:i+input_len+output_len]\n",
    "\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)  # [1, input_len, 1]\n",
    "\n",
    "        pred = model(input_tensor)\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.squeeze(0).squeeze(-1)\n",
    "        else:\n",
    "            pred = pred.squeeze(0)\n",
    "\n",
    "        # Convert prediction & ground truth to TimeSeries\n",
    "        pred_ts = TimeSeries.from_times_and_values(true_time, pred.cpu().numpy())\n",
    "        true_ts = TimeSeries.from_times_and_values(true_time, true_output)\n",
    "\n",
    "        # Inverse transform\n",
    "        pred_unscaled = transformer.inverse_transform(pred_ts)\n",
    "        true_unscaled = transformer.inverse_transform(true_ts)\n",
    "\n",
    "        predictions_ts_list.append(pred_unscaled)\n",
    "        ground_truth_ts_list.append(true_unscaled)\n",
    "\n",
    "    return predictions_ts_list, ground_truth_ts_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3ec654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_predictions_csv(model_name: str, cid: int,aggr_strat: str ,rounds: list, model_dir: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    For each round, load the model, predict on test set for cid, and save all preds in a single CSV.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for rnd in tqdm(rounds):\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_round_{rnd}_{aggr_strat}.pt\")\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"[WARN] Model not found: {model_path}\")\n",
    "            continue\n",
    "\n",
    "        model = model_fn(model_name)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "        model.eval()\n",
    "\n",
    "        pred_ts_list, gt_ts_list = rolling_forecast_on_test(cid=cid, model=model)\n",
    "\n",
    "        for pred_ts, true_ts in zip(pred_ts_list, gt_ts_list):\n",
    "            df_pred = pd.DataFrame({\"timestamp\": pred_ts.time_index, \"pred\": pred_ts.values().squeeze()})\n",
    "            df_true = pd.DataFrame({\"timestamp\": true_ts.time_index, \"true\": true_ts.values().squeeze()})\n",
    "\n",
    "            # df_merged = df_true.join(df_pred, how=\"inner\")\n",
    "            df_merged = pd.merge(df_true, df_pred, on=\"timestamp\", how=\"inner\")\n",
    "            df_merged[\"round\"] = rnd\n",
    "\n",
    "\n",
    "            rows.append(df_merged[[\"timestamp\", \"true\", \"pred\", \"round\"]])\n",
    "\n",
    "    # Combine all rows\n",
    "    final_df = pd.concat(rows, ignore_index=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"[INFO] Forecasts written to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f823c5",
   "metadata": {},
   "source": [
    "## for each building id store pred - cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9da6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_model_predictions_csv_building(model_name: str, cid: int,aggr_strat: str ,rounds: list, model_dir: str, output_csv: str):\n",
    "#     \"\"\"\n",
    "#     For each round, load the model, predict on test set for cid, and save all preds in a single CSV.\n",
    "#     \"\"\"\n",
    "#     rows = []\n",
    "\n",
    "#     for rnd in tqdm(rounds):\n",
    "#         model_path = os.path.join(model_dir, f\"{model_name}_round_{rnd}_{aggr_strat}.pt\")\n",
    "\n",
    "#         if not os.path.exists(model_path):\n",
    "#             print(f\"[WARN] Model not found: {model_path}\")\n",
    "#             continue\n",
    "\n",
    "#         model = model_fn(model_name)\n",
    "#         model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "#         model.eval()\n",
    "\n",
    "#         pred_ts_list, gt_ts_list = rolling_forecast_on_test(cid=cid, model=model)\n",
    "\n",
    "#         for pred_ts, true_ts in zip(pred_ts_list, gt_ts_list):\n",
    "#             df_pred = pd.DataFrame({\"timestamp\": pred_ts.time_index, \"pred\": pred_ts.values().squeeze()})\n",
    "#             df_true = pd.DataFrame({\"timestamp\": true_ts.time_index, \"true\": true_ts.values().squeeze()})\n",
    "\n",
    "#             # df_merged = df_true.join(df_pred, how=\"inner\")\n",
    "#             df_merged = pd.merge(df_true, df_pred, on=\"timestamp\", how=\"inner\")\n",
    "#             df_merged[\"round\"] = rnd\n",
    "\n",
    "\n",
    "#             rows.append(df_merged[[\"timestamp\", \"true\", \"pred\", \"round\"]])\n",
    "\n",
    "#     # Combine all rows\n",
    "#     final_df = pd.concat(rows, ignore_index=True)\n",
    "#     final_df.to_csv(output_csv, index=False)\n",
    "#     print(f\"[INFO] Forecasts written to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd668f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_model_predictions_csv(\n",
    "#     model_name=\"gru\",\n",
    "#     cid=42,\n",
    "#     rounds=[1, 2, 3, 4, 5],\n",
    "#     model_dir=\"results/gru\",\n",
    "#     output_csv=\"gru_rolling_predictions.csv\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de050a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    return np.mean(np.where(denominator == 0, 0, np.abs(y_true - y_pred) / denominator)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error.\"\"\"\n",
    "    y_true = np.where(y_true == 0, 1e-8, y_true)  # avoid division by zero\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def evaluate_forecast_metrics_per_round(csv_path):\n",
    "    \"\"\"\n",
    "    Reads forecast CSV and computes MAPE, MAE, SMAPE, RMSE, and MSE per round.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV with columns: timestamp, true, pred, round\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Metrics summary per round\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"CSV is empty or invalid\")\n",
    "\n",
    "    metrics_list = []\n",
    "\n",
    "    for rnd in sorted(df['round'].unique()):\n",
    "        df_rnd = df[df['round'] == rnd]\n",
    "        y_true = df_rnd[\"true\"].values\n",
    "        y_pred = df_rnd[\"pred\"].values\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape_val = mape(y_true, y_pred)\n",
    "        smape_val = smape(y_true, y_pred)\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"round\": rnd,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE (%)\": mape_val,\n",
    "            \"SMAPE (%)\": smape_val\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a3696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gru\"\n",
    "CID = 45\n",
    "ROUND = [1,2,3,4,5,6,7,8,9]\n",
    "MODEL_DIR = f\"results/{MODEL_NAME}\"\n",
    "STRATEGY = \"kr\"\n",
    "OUTPUT_DIR = f\"predictions/{CID}_{MODEL_NAME}_{STRATEGY}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5964899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'meter_0_data_cleaned.feather'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_model_predictions_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROUND\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43maggr_strat\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTRATEGY\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mget_model_predictions_csv\u001b[39m\u001b[34m(model_name, cid, aggr_strat, rounds, model_dir, output_csv)\u001b[39m\n\u001b[32m     15\u001b[39m model.load_state_dict(torch.load(model_path, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     16\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m pred_ts_list, gt_ts_list = \u001b[43mrolling_forecast_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred_ts, true_ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pred_ts_list, gt_ts_list):\n\u001b[32m     21\u001b[39m     df_pred = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.time_index, \u001b[33m\"\u001b[39m\u001b[33mpred\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.values().squeeze()})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mrolling_forecast_on_test\u001b[39m\u001b[34m(cid, model, filepath, input_len, output_len)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mPerform rolling window forecast on the test data using a trained model and return\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03munscaled predictions and ground truths with actual timestamps.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m    Tuple[List[TimeSeries], List[TimeSeries]]: (predictions_ts_list, ground_truth_ts_list)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Load and filter data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m df = df[df[\u001b[33m'\u001b[39m\u001b[33mbuilding_id\u001b[39m\u001b[33m'\u001b[39m] == cid]\n\u001b[32m     21\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mmeter_reading\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mmeter_reading\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/io/feather_format.py:119\u001b[39m, in \u001b[36mread_feather\u001b[39m\u001b[34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m    117\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib.no_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_string_dtype():\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m feather.read_feather(\n\u001b[32m    124\u001b[39m             handles.handle, columns=columns, use_threads=\u001b[38;5;28mbool\u001b[39m(use_threads)\n\u001b[32m    125\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'meter_0_data_cleaned.feather'"
     ]
    }
   ],
   "source": [
    "get_model_predictions_csv(\n",
    "    model_name=MODEL_NAME,\n",
    "    cid=CID,\n",
    "    rounds=ROUND,\n",
    "    model_dir=MODEL_DIR,\n",
    "    output_csv=OUTPUT_DIR,\n",
    "    aggr_strat= STRATEGY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1477a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " round      MAE       MSE     RMSE   MAPE (%)  SMAPE (%)\n",
      "     1 1.923647  4.500009 2.121322  69.997375 114.260351\n",
      "     2 1.255574  2.282222 1.510702  43.709379  60.022051\n",
      "     3 0.854270  1.111473 1.054264  31.378716  35.242188\n",
      "     4 2.027142  4.629476 2.151622  76.801186 126.530583\n",
      "     5 1.852406  4.092056 2.022883  70.587240 110.434803\n",
      "     6 1.770699  4.543252 2.131491  71.250029  94.049303\n",
      "     7 4.777556 24.926722 4.992667 191.032033 197.836468\n",
      "     8 4.177765 24.706141 4.970527 170.923942 155.682856\n",
      "     9 2.760312 11.990074 3.462669 106.734097 119.880668\n"
     ]
    }
   ],
   "source": [
    "metrics_df = evaluate_forecast_metrics_per_round(OUTPUT_DIR)\n",
    "print(metrics_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gru\"\n",
    "CID = 5\n",
    "ROUND = [1,2,3,4,5,6,7,8,9]\n",
    "MODEL_DIR = f\"results/{MODEL_NAME}\"\n",
    "STRATEGY = \"fedAvg\"\n",
    "OUTPUT_DIR = f\"predictions/{CID}_{MODEL_NAME}_{STRATEGY}.csv\"\n",
    "\n",
    "get_model_predictions_csv(\n",
    "    model_name=MODEL_NAME,\n",
    "    cid=CID,\n",
    "    rounds=ROUND,\n",
    "    model_dir=MODEL_DIR,\n",
    "    output_csv=OUTPUT_DIR,\n",
    "    aggr_strat= STRATEGY\n",
    ")\n",
    "\n",
    "metrics_df = evaluate_forecast_metrics_per_round(OUTPUT_DIR)\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae0148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Model: gru, Strategy: fedAvg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:11<01:34, 11.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m▶ Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Run prediction and save CSV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mget_model_predictions_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROUNDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggr_strat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Compute and save metrics\u001b[39;00m\n\u001b[32m     34\u001b[39m     metrics_df = evaluate_forecast_metrics_per_round(output_csv)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mget_model_predictions_csv\u001b[39m\u001b[34m(model_name, cid, aggr_strat, rounds, model_dir, output_csv)\u001b[39m\n\u001b[32m     15\u001b[39m model.load_state_dict(torch.load(model_path, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     16\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m pred_ts_list, gt_ts_list = \u001b[43mrolling_forecast_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred_ts, true_ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pred_ts_list, gt_ts_list):\n\u001b[32m     21\u001b[39m     df_pred = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.time_index, \u001b[33m\"\u001b[39m\u001b[33mpred\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.values().squeeze()})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mrolling_forecast_on_test\u001b[39m\u001b[34m(cid, model, filepath, input_len, output_len)\u001b[39m\n\u001b[32m     62\u001b[39m     pred = pred.squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Convert prediction & ground truth to TimeSeries\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m pred_ts = \u001b[43mTimeSeries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_times_and_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m true_ts = TimeSeries.from_times_and_values(true_time, true_output)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Inverse transform\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/darts/timeseries.py:1323\u001b[39m, in \u001b[36mTimeSeries.from_times_and_values\u001b[39m\u001b[34m(cls, times, values, fill_missing_dates, freq, columns, fillna_value, static_covariates, hierarchy, metadata)\u001b[39m\n\u001b[32m   1311\u001b[39m     coords[DIMS[\u001b[32m1\u001b[39m]] = columns\n\u001b[32m   1313\u001b[39m xa = xr.DataArray(\n\u001b[32m   1314\u001b[39m     values,\n\u001b[32m   1315\u001b[39m     dims=(times_name,) + DIMS[-\u001b[32m2\u001b[39m:],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1321\u001b[39m     },\n\u001b[32m   1322\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_xarray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/darts/timeseries.py:485\u001b[39m, in \u001b[36mTimeSeries.from_xarray\u001b[39m\u001b[34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[39m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clist\n\u001b[32m    484\u001b[39m time_index_name = xa_.dims[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m columns_list = \u001b[43m_clean_component_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# Note: an option here could be to also rename the component names in the static covariates\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# and/or hierarchy, if any. However, we decide not to do so as those are directly dependent on the\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[38;5;66;03m# component names to work properly, so in case there's any name conflict it's better solved\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    500\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# ```\u001b[39;00m\n\u001b[32m    502\u001b[39m xa_ = xr.DataArray(\n\u001b[32m    503\u001b[39m     xa_.values,\n\u001b[32m    504\u001b[39m     dims=xa_.dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     attrs=xa_.attrs,\n\u001b[32m    510\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/darts/timeseries.py:462\u001b[39m, in \u001b[36mTimeSeries.from_xarray.<locals>._clean_component_list\u001b[39m\u001b[34m(columns)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clean_component_list\u001b[39m(columns) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# return a list of string containing column names\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# make each column name unique in case some columns have the same names\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     clist = \u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# convert everything to string if needed\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clist):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/core/base.py:832\u001b[39m, in \u001b[36mIndexOpsMixin.tolist\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtolist\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    799\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    800\u001b[39m \u001b[33;03m    Return a list of the values.\u001b[39;00m\n\u001b[32m    801\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    830\u001b[39m \u001b[33;03m    [1, 2, 3]\u001b[39;00m\n\u001b[32m    831\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/core/indexes/base.py:5168\u001b[39m, in \u001b[36mIndex._values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5144\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   5145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ExtensionArray | np.ndarray:\n\u001b[32m   5146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5147\u001b[39m \u001b[33;03m    The best array representation.\u001b[39;00m\n\u001b[32m   5148\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5166\u001b[39m \u001b[33;03m    values : Values\u001b[39;00m\n\u001b[32m   5167\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mproperties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/pandas/core/indexes/range.py:244\u001b[39m, in \u001b[36mRangeIndex._data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m    An int array that for performance reasons is created only when needed.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m    The constructed array is saved in ``_cache``.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.arange(\u001b[38;5;28mself\u001b[39m.start, \u001b[38;5;28mself\u001b[39m.stop, \u001b[38;5;28mself\u001b[39m.step, dtype=np.int64)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurations\n",
    "MODELS = [\"gru\", \"lstm\", \"moe_gru\", \"moe_lstm\"]\n",
    "# STRATEGIES = [\"fedAvg\", \"fedAvgM\", \"kr_norm\", \"kr\", \"kr_sft\"]\n",
    "STRATEGIES = [\"fedAvg\",\"fedAvgM\",\"diff\", \"diff2\", \"diff_rev\", \"scaffold\"]\n",
    "# CID = 879\n",
    "ROUNDS = list(range(7, 11))\n",
    "BASE_RESULTS_DIR = \"results\"\n",
    "BASE_OUTPUT_DIR = \"predictions\"\n",
    "METRICS_DIR = \"metrics\"\n",
    "# return rolling forecast - prediction - true add this in new csv with building_id \n",
    "\n",
    "\n",
    "# Create directories if needed\n",
    "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "for CID in range(1411):\n",
    "    for model_name in MODELS:\n",
    "        for strategy in STRATEGIES:\n",
    "            model_dir = os.path.join(BASE_RESULTS_DIR, model_name)\n",
    "            output_csv = os.path.join(BASE_OUTPUT_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "            metrics_csv = os.path.join(METRICS_DIR, f\"cid{CID}_{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "            print(f\"\\n▶ Model: {model_name}, Strategy: {strategy}\")\n",
    "\n",
    "            try:\n",
    "                # Run prediction and save CSV\n",
    "                get_model_predictions_csv(\n",
    "                    model_name=model_name,\n",
    "                    cid=CID,\n",
    "                    rounds=ROUNDS,\n",
    "                    model_dir=model_dir,\n",
    "                    output_csv=output_csv,\n",
    "                    aggr_strat=strategy\n",
    "                )\n",
    "\n",
    "                # Compute and save metrics\n",
    "                metrics_df = evaluate_forecast_metrics_per_round(output_csv)\n",
    "                metrics_df.to_csv(metrics_csv, index=False)\n",
    "\n",
    "                print(f\"Metrics saved to {metrics_csv}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] model={model_name}, strategy={strategy}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b7ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af00999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bd948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90964b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
