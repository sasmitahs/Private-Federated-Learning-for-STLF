{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c26839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57bad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_weights(weights_list):\n",
    "#     \"\"\"Averages model weights provided as a list of get_weights outputs.\"\"\"\n",
    "#     avg_weights = []\n",
    "#     num_models = len(weights_list)\n",
    "#     for layer_weights in zip(*weights_list):\n",
    "#         avg_layer = np.mean(np.array(layer_weights), axis=0)\n",
    "#         avg_weights.append(avg_layer)\n",
    "#     return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf3f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"train_final.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5334f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>air_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>72.221012</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>39.611586</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593146</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>1.920567</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593147</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>111.532464</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593148</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21 01:00:00</td>\n",
       "      <td>456.734799</td>\n",
       "      <td>Education</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter           timestamp  meter_reading primary_use  \\\n",
       "7593144            0      0 2016-05-21 01:00:00      72.221012   Education   \n",
       "7593145            1      0 2016-05-21 01:00:00      39.611586   Education   \n",
       "7593146            2      0 2016-05-21 01:00:00       1.920567   Education   \n",
       "7593147            3      0 2016-05-21 01:00:00     111.532464   Education   \n",
       "7593148            4      0 2016-05-21 01:00:00     456.734799   Education   \n",
       "\n",
       "         air_temperature  \n",
       "7593144             25.6  \n",
       "7593145             25.6  \n",
       "7593146             25.6  \n",
       "7593147             25.6  \n",
       "7593148             25.6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1317d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11712248 entries, 7593144 to 20216099\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   building_id      int64         \n",
      " 1   meter            int64         \n",
      " 2   timestamp        datetime64[ns]\n",
      " 3   meter_reading    float64       \n",
      " 4   primary_use      object        \n",
      " 5   air_temperature  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(1)\n",
      "memory usage: 625.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1410\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f443db",
   "metadata": {},
   "source": [
    "### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ed70787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:25<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_fedAvg.pt\n",
      "Round 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:51<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_fedAvg.pt\n",
      "Round 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:53<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_fedAvg.pt\n",
      "Round 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:53<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_fedAvg.pt\n",
      "Round 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:56<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_5_fedAvg.pt\n",
      "Round 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_6_fedAvg.pt\n",
      "Round 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_7_fedAvg.pt\n",
      "Round 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:55<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_8_fedAvg.pt\n",
      "Round 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:56<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_9_fedAvg.pt\n",
      "Round 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_10_fedAvg.pt\n",
      "Round 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:54<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_11_fedAvg.pt\n",
      "Round 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:49<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_12_fedAvg.pt\n",
      "Round 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:54<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_13_fedAvg.pt\n",
      "Round 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:54<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_14_fedAvg.pt\n",
      "Round 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_15_fedAvg.pt\n",
      "Round 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:55<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_16_fedAvg.pt\n",
      "Round 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_17_fedAvg.pt\n",
      "Round 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_18_fedAvg.pt\n",
      "Round 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:59<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_19_fedAvg.pt\n",
      "Round 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:56<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_20_fedAvg.pt\n",
      "Round 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_21_fedAvg.pt\n",
      "Round 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_22_fedAvg.pt\n",
      "Round 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_23_fedAvg.pt\n",
      "Round 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_24_fedAvg.pt\n",
      "Round 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_25_fedAvg.pt\n",
      "Round 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_26_fedAvg.pt\n",
      "Round 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:59<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_27_fedAvg.pt\n",
      "Round 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_28_fedAvg.pt\n",
      "Round 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:02<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_29_fedAvg.pt\n",
      "Round 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_30_fedAvg.pt\n",
      "Round 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_31_fedAvg.pt\n",
      "Round 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:54<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_32_fedAvg.pt\n",
      "Round 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_33_fedAvg.pt\n",
      "Round 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:02<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_34_fedAvg.pt\n",
      "Round 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:58<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_35_fedAvg.pt\n",
      "Round 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:56<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_36_fedAvg.pt\n",
      "Round 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:02<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_37_fedAvg.pt\n",
      "Round 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:58<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_38_fedAvg.pt\n",
      "Round 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:00<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_39_fedAvg.pt\n",
      "Round 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_40_fedAvg.pt\n",
      "Round 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:55<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_41_fedAvg.pt\n",
      "Round 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_42_fedAvg.pt\n",
      "Round 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_43_fedAvg.pt\n",
      "Round 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:56<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_44_fedAvg.pt\n",
      "Round 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:59<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_45_fedAvg.pt\n",
      "Round 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:52<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_46_fedAvg.pt\n",
      "Round 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:58<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_47_fedAvg.pt\n",
      "Round 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:59<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_48_fedAvg.pt\n",
      "Round 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:57<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_49_fedAvg.pt\n",
      "Round 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [03:59<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_50_fedAvg.pt\n",
      "Starting experiment with model: gru\n",
      "Round 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_1_fedAvg.pt\n",
      "Round 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_2_fedAvg.pt\n",
      "Round 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_3_fedAvg.pt\n",
      "Round 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_4_fedAvg.pt\n",
      "Round 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:09<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_5_fedAvg.pt\n",
      "Round 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_6_fedAvg.pt\n",
      "Round 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_7_fedAvg.pt\n",
      "Round 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:07<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_8_fedAvg.pt\n",
      "Round 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_9_fedAvg.pt\n",
      "Round 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:08<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_10_fedAvg.pt\n",
      "Round 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_11_fedAvg.pt\n",
      "Round 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_12_fedAvg.pt\n",
      "Round 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_13_fedAvg.pt\n",
      "Round 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_14_fedAvg.pt\n",
      "Round 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_15_fedAvg.pt\n",
      "Round 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_16_fedAvg.pt\n",
      "Round 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_17_fedAvg.pt\n",
      "Round 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_18_fedAvg.pt\n",
      "Round 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_19_fedAvg.pt\n",
      "Round 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_20_fedAvg.pt\n",
      "Round 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_21_fedAvg.pt\n",
      "Round 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_22_fedAvg.pt\n",
      "Round 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:19<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_23_fedAvg.pt\n",
      "Round 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_24_fedAvg.pt\n",
      "Round 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:14<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_25_fedAvg.pt\n",
      "Round 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_26_fedAvg.pt\n",
      "Round 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_27_fedAvg.pt\n",
      "Round 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_28_fedAvg.pt\n",
      "Round 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_29_fedAvg.pt\n",
      "Round 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_30_fedAvg.pt\n",
      "Round 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_31_fedAvg.pt\n",
      "Round 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_32_fedAvg.pt\n",
      "Round 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:14<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_33_fedAvg.pt\n",
      "Round 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_34_fedAvg.pt\n",
      "Round 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_35_fedAvg.pt\n",
      "Round 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_36_fedAvg.pt\n",
      "Round 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_37_fedAvg.pt\n",
      "Round 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_38_fedAvg.pt\n",
      "Round 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_39_fedAvg.pt\n",
      "Round 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_40_fedAvg.pt\n",
      "Round 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_41_fedAvg.pt\n",
      "Round 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:18<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_42_fedAvg.pt\n",
      "Round 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_43_fedAvg.pt\n",
      "Round 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:14<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_44_fedAvg.pt\n",
      "Round 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_45_fedAvg.pt\n",
      "Round 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_46_fedAvg.pt\n",
      "Round 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_47_fedAvg.pt\n",
      "Round 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_48_fedAvg.pt\n",
      "Round 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_49_fedAvg.pt\n",
      "Round 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|██████████| 211/211 [04:17<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/gru/gru_round_50_fedAvg.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1244302",
   "metadata": {},
   "source": [
    "### DiffAware FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f050b",
   "metadata": {},
   "source": [
    "### Diff-Aware Fed Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5908746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDifficultyWeight:\n",
    "    def __init__(self, num_clients, accumulate_iters=20):\n",
    "        self.num_clients = num_clients\n",
    "        self.last_loss = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.learn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.unlearn_score = torch.zeros(num_clients).float().to(DEVICE)\n",
    "        self.ema_difficulty = torch.ones(num_clients).float().to(DEVICE)\n",
    "        self.accumulate_iters = accumulate_iters\n",
    "\n",
    "    def update(self, cid: int, loss_history: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Update difficulty based on loss trend for a client.\n",
    "        Expects a list of per-epoch losses.\n",
    "        \"\"\"\n",
    "        current_loss = torch.tensor(loss_history[-1], dtype=torch.float32).to(DEVICE)\n",
    "        previous_loss = self.last_loss[cid]\n",
    "        delta = current_loss - previous_loss\n",
    "        ratio = torch.log((current_loss + 1e-8) / (previous_loss + 1e-8))\n",
    "\n",
    "        learn = torch.where(delta < 0, -delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "        unlearn = torch.where(delta >= 0, delta * ratio, torch.tensor(0.0, device=current_loss.device))\n",
    "\n",
    "        # EMA update\n",
    "        momentum = (self.accumulate_iters - 1) / self.accumulate_iters\n",
    "        self.learn_score[cid] = momentum * self.learn_score[cid] + (1 - momentum) * learn\n",
    "        self.unlearn_score[cid] = momentum * self.unlearn_score[cid] + (1 - momentum) * unlearn\n",
    "\n",
    "        # Difficulty score\n",
    "        diff_ratio = (self.unlearn_score[cid] + 1e-8) / (self.learn_score[cid] + 1e-8)\n",
    "        difficulty = diff_ratio #torch.pow(diff_ratio, 1 / 5)\n",
    "\n",
    "        # Smooth difficulty over rounds\n",
    "        self.ema_difficulty[cid] = momentum * self.ema_difficulty[cid] + (1 - momentum) * difficulty\n",
    "\n",
    "        self.last_loss[cid] = current_loss\n",
    "        return self.ema_difficulty[cid].item()\n",
    "\n",
    "    def get_normalized_weights(self, client_ids: List[int]) -> List[float]:\n",
    "        weights = [self.ema_difficulty[cid].item() for cid in client_ids]\n",
    "        total = sum(weights)\n",
    "        if total == 0:\n",
    "            return [1.0 / len(client_ids)] * len(client_ids)\n",
    "        return [w / total for w in weights]\n",
    "    \n",
    "    def get_sampling_probabilities(self, min_prob=0.05):\n",
    "        difficulty = self.ema_difficulty\n",
    "        inv_difficulty = 1.0 / (difficulty + 1e-6)\n",
    "        inv_difficulty = inv_difficulty / inv_difficulty.sum()\n",
    "        probs = torch.clamp(inv_difficulty, min=min_prob)\n",
    "        return (probs / probs.sum()).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f9164",
   "metadata": {},
   "source": [
    "## SCAFFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f5aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_scaffold(\n",
    "    local_model,\n",
    "    train_loader,         # global_model, train_loader\n",
    "    global_weights,    # x\n",
    "    server_c,          # c\n",
    "    client_ci,         # cᵢ\n",
    "    device=DEVICE,\n",
    "    learning_rate= LR,\n",
    "    loss_fn=None,\n",
    "    optimizer_class=optim.Adam,\n",
    "    epochs= LOCAL_EPOCHS  # 50\n",
    "):\n",
    "    \"\"\"Train client with SCAFFOLD correction. Return Δy, Δc, new cᵢ, final weights.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # print(f\"[DEBUG] Training on: {device}\")\n",
    "\n",
    "    \n",
    "    local_model.to(device)\n",
    "    loss_fn = loss_fn or nn.MSELoss()\n",
    "    optimizer = optimizer_class(local_model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    local_model.train()\n",
    "    total_steps = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            if y_batch.dim() == 3 and y_batch.shape[-1] == 1:\n",
    "                y_batch = y_batch.squeeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = local_model(X_batch)\n",
    "            loss = loss_fn(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ✅ SCAFFOLD correction: adjust each param after normal SGD step  # doubt at this step\n",
    "            with torch.no_grad():\n",
    "                for p, sc_np, ci_np in zip(local_model.parameters(), server_c, client_ci):\n",
    "                    sc_tensor = torch.tensor(sc_np, dtype=p.dtype, device=p.device)\n",
    "                    ci_tensor = torch.tensor(ci_np, dtype=p.dtype, device=p.device)\n",
    "                    p -= learning_rate * (sc_tensor - ci_tensor)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total_steps += 1\n",
    "        \n",
    "        loss_history.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    # Compute deltas\n",
    "    local_weights = get_weights(local_model)\n",
    "    delta_y = [lw - gw for lw, gw in zip(local_weights, global_weights)]\n",
    "\n",
    "    # K = total_steps\n",
    "    K = total_steps\n",
    "    new_ci = []\n",
    "    delta_c = []\n",
    "\n",
    "    for gw, lw, ci, sc in zip(global_weights, local_weights, client_ci, server_c):\n",
    "        ci_new = ci - sc + (gw - lw) / (K * learning_rate)\n",
    "        new_ci.append(ci_new)  # doubt can overide new_ci\n",
    "        delta_c.append(ci_new - ci)\n",
    "\n",
    "    return delta_y, delta_c, new_ci, local_weights, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b4043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Using device: cuda\n",
      "Round 1/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [08:16<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_1_scaffold_diff001.pt\n",
      "Round 2/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [08:29<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_2_scaffold_diff001.pt\n",
      "Round 3/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_3_scaffold_diff001.pt\n",
      "Round 4/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:25<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_4_scaffold_diff001.pt\n",
      "Round 5/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:25<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_5_scaffold_diff001.pt\n",
      "Round 6/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:23<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_6_scaffold_diff001.pt\n",
      "Round 7/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_7_scaffold_diff001.pt\n",
      "Round 8/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:08<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_8_scaffold_diff001.pt\n",
      "Round 9/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_9_scaffold_diff001.pt\n",
      "Round 10/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:59<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_10_scaffold_diff001.pt\n",
      "Round 11/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:11<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_11_scaffold_diff001.pt\n",
      "Round 12/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:00<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_12_scaffold_diff001.pt\n",
      "Round 13/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_13_scaffold_diff001.pt\n",
      "Round 14/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:03<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_14_scaffold_diff001.pt\n",
      "Round 15/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:08<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_15_scaffold_diff001.pt\n",
      "Round 16/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:00<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_16_scaffold_diff001.pt\n",
      "Round 17/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:08<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_17_scaffold_diff001.pt\n",
      "Round 18/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_18_scaffold_diff001.pt\n",
      "Round 19/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_19_scaffold_diff001.pt\n",
      "Round 20/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_20_scaffold_diff001.pt\n",
      "Round 21/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:10<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_21_scaffold_diff001.pt\n",
      "Round 22/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_22_scaffold_diff001.pt\n",
      "Round 23/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_23_scaffold_diff001.pt\n",
      "Round 24/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_24_scaffold_diff001.pt\n",
      "Round 25/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_25_scaffold_diff001.pt\n",
      "Round 26/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:08<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_26_scaffold_diff001.pt\n",
      "Round 27/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:08<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_27_scaffold_diff001.pt\n",
      "Round 28/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:02<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_28_scaffold_diff001.pt\n",
      "Round 29/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:03<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_29_scaffold_diff001.pt\n",
      "Round 30/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_30_scaffold_diff001.pt\n",
      "Round 31/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_31_scaffold_diff001.pt\n",
      "Round 32/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:17<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_32_scaffold_diff001.pt\n",
      "Round 33/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_33_scaffold_diff001.pt\n",
      "Round 34/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:10<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_34_scaffold_diff001.pt\n",
      "Round 35/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_35_scaffold_diff001.pt\n",
      "Round 36/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_36_scaffold_diff001.pt\n",
      "Round 37/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_37_scaffold_diff001.pt\n",
      "Round 38/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_38_scaffold_diff001.pt\n",
      "Round 39/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_39_scaffold_diff001.pt\n",
      "Round 40/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:58<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_40_scaffold_diff001.pt\n",
      "Round 41/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:18<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_41_scaffold_diff001.pt\n",
      "Round 42/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_42_scaffold_diff001.pt\n",
      "Round 43/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:55<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_43_scaffold_diff001.pt\n",
      "Round 44/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_44_scaffold_diff001.pt\n",
      "Round 45/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_45_scaffold_diff001.pt\n",
      "Round 46/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_46_scaffold_diff001.pt\n",
      "Round 47/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:15<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_47_scaffold_diff001.pt\n",
      "Round 48/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_48_scaffold_diff001.pt\n",
      "Round 49/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:18<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_49_scaffold_diff001.pt\n",
      "Round 50/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_50_scaffold_diff001.pt\n",
      "Starting experiment with model: gru\n",
      "Using device: cuda\n",
      "Round 1/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_1_scaffold_diff001.pt\n",
      "Round 2/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:33<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_2_scaffold_diff001.pt\n",
      "Round 3/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:20<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_3_scaffold_diff001.pt\n",
      "Round 4/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:23<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_4_scaffold_diff001.pt\n",
      "Round 5/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_5_scaffold_diff001.pt\n",
      "Round 6/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_6_scaffold_diff001.pt\n",
      "Round 7/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_7_scaffold_diff001.pt\n",
      "Round 8/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_8_scaffold_diff001.pt\n",
      "Round 9/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:33<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_9_scaffold_diff001.pt\n",
      "Round 10/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:30<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_10_scaffold_diff001.pt\n",
      "Round 11/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_11_scaffold_diff001.pt\n",
      "Round 12/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_12_scaffold_diff001.pt\n",
      "Round 13/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_13_scaffold_diff001.pt\n",
      "Round 14/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_14_scaffold_diff001.pt\n",
      "Round 15/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:31<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_15_scaffold_diff001.pt\n",
      "Round 16/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:27<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_16_scaffold_diff001.pt\n",
      "Round 17/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_17_scaffold_diff001.pt\n",
      "Round 18/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:27<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_18_scaffold_diff001.pt\n",
      "Round 19/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:28<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_19_scaffold_diff001.pt\n",
      "Round 20/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_20_scaffold_diff001.pt\n",
      "Round 21/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:31<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_21_scaffold_diff001.pt\n",
      "Round 22/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:28<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_22_scaffold_diff001.pt\n",
      "Round 23/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:29<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_23_scaffold_diff001.pt\n",
      "Round 24/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:36<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_24_scaffold_diff001.pt\n",
      "Round 25/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:34<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_25_scaffold_diff001.pt\n",
      "Round 26/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:31<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_26_scaffold_diff001.pt\n",
      "Round 27/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_27_scaffold_diff001.pt\n",
      "Round 28/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_28_scaffold_diff001.pt\n",
      "Round 29/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:41<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_29_scaffold_diff001.pt\n",
      "Round 30/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:33<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_30_scaffold_diff001.pt\n",
      "Round 31/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:33<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_31_scaffold_diff001.pt\n",
      "Round 32/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_32_scaffold_diff001.pt\n",
      "Round 33/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:35<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_33_scaffold_diff001.pt\n",
      "Round 34/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_34_scaffold_diff001.pt\n",
      "Round 35/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:37<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_35_scaffold_diff001.pt\n",
      "Round 36/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_36_scaffold_diff001.pt\n",
      "Round 37/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:26<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_37_scaffold_diff001.pt\n",
      "Round 38/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:00<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_38_scaffold_diff001.pt\n",
      "Round 39/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:03<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_39_scaffold_diff001.pt\n",
      "Round 40/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:57<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_40_scaffold_diff001.pt\n",
      "Round 41/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_41_scaffold_diff001.pt\n",
      "Round 42/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:03<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_42_scaffold_diff001.pt\n",
      "Round 43/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_43_scaffold_diff001.pt\n",
      "Round 44/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:00<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_44_scaffold_diff001.pt\n",
      "Round 45/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_45_scaffold_diff001.pt\n",
      "Round 46/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:05<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_46_scaffold_diff001.pt\n",
      "Round 47/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_47_scaffold_diff001.pt\n",
      "Round 48/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_48_scaffold_diff001.pt\n",
      "Round 49/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_49_scaffold_diff001.pt\n",
      "Round 50/50\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:01<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_50_scaffold_diff001.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    difficulty_tracker = TimeSeriesDifficultyWeight(num_clients=NUM_CLIENTS)\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    server_c = [np.zeros_like(w) for w in global_weights]\n",
    "    client_cs = {cid: [np.zeros_like(w) for w in global_weights] for cid in range(NUM_CLIENTS)}\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        # === Difficulty-aware sampling ===\n",
    "        sampling_probs = difficulty_tracker.get_sampling_probabilities(min_prob=0.001)\n",
    "        sampled_clients = np.random.choice(\n",
    "            np.arange(NUM_CLIENTS),\n",
    "            size=int(CLIENT_FRAC * NUM_CLIENTS),\n",
    "            replace=False,\n",
    "            p=sampling_probs\n",
    "        )\n",
    "        print(f\"Sampled {len(sampled_clients)} clients\")\n",
    "\n",
    "        local_weight_deltas = []\n",
    "        local_c_deltas = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "\n",
    "            train_loader, _ = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            delta_y, delta_c, new_ci, local_weights, loss_history = train_model_scaffold(\n",
    "                local_model, train_loader,\n",
    "                global_weights=global_weights,\n",
    "                server_c=server_c,\n",
    "                client_ci=client_cs[cid],\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "\n",
    "            # === Difficulty update ===\n",
    "            difficulty_tracker.update(cid, loss_history)\n",
    "\n",
    "            local_weight_deltas.append(delta_y)\n",
    "            local_c_deltas.append(delta_c)\n",
    "            client_cs[cid] = new_ci\n",
    "\n",
    "        # === Aggregate and update global weights ===\n",
    "        mean_delta_y = average_weights(local_weight_deltas)\n",
    "        global_weights = [gw + mean_delta_y[i] for i, gw in enumerate(global_weights)]\n",
    "\n",
    "        mean_delta_c = average_weights(local_c_deltas)\n",
    "        frac = len(sampled_clients) / NUM_CLIENTS\n",
    "        server_c = [sc + frac * mean_delta_c[i] for i, sc in enumerate(server_c)]\n",
    "\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        ckpt_path = os.path.join(\"results\", model_name, f\"{model_name}_round_{rnd+1}_scaffold_diff001.pt\")\n",
    "        torch.save(global_model.state_dict(), ckpt_path)\n",
    "        print(f\"Saved: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0470873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a098f7",
   "metadata": {},
   "source": [
    "## SCAFFOLD without Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e059403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71f176f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Using device: cuda\n",
      "Round 1/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:35<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_1_scaffold_sr.pt\n",
      "Round 2/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:46<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_2_scaffold_sr.pt\n",
      "Round 3/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:54<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_3_scaffold_sr.pt\n",
      "Round 4/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:49<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_4_scaffold_sr.pt\n",
      "Round 5/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:46<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/lstm/lstm_round_5_scaffold_sr.pt\n",
      "Starting experiment with model: gru\n",
      "Using device: cuda\n",
      "Round 1/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:39<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_1_scaffold_sr.pt\n",
      "Round 2/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [06:41<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_2_scaffold_sr.pt\n",
      "Round 3/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:07<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_3_scaffold_sr.pt\n",
      "Round 4/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:12<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_4_scaffold_sr.pt\n",
      "Round 5/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:15<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/gru/gru_round_5_scaffold_sr.pt\n",
      "Starting experiment with model: moe_lstm\n",
      "Using device: cuda\n",
      "Round 1/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [09:40<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_lstm/moe_lstm_round_1_scaffold_sr.pt\n",
      "Round 2/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_lstm/moe_lstm_round_2_scaffold_sr.pt\n",
      "Round 3/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [10:07<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_lstm/moe_lstm_round_3_scaffold_sr.pt\n",
      "Round 4/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [10:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_lstm/moe_lstm_round_4_scaffold_sr.pt\n",
      "Round 5/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [08:27<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_lstm/moe_lstm_round_5_scaffold_sr.pt\n",
      "Starting experiment with model: moe_gru\n",
      "Using device: cuda\n",
      "Round 1/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [08:37<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_gru/moe_gru_round_1_scaffold_sr.pt\n",
      "Round 2/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [08:03<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_gru/moe_gru_round_2_scaffold_sr.pt\n",
      "Round 3/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:26<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_gru/moe_gru_round_3_scaffold_sr.pt\n",
      "Round 4/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:33<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_gru/moe_gru_round_4_scaffold_sr.pt\n",
      "Round 5/5\n",
      "Sampled 211 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [07:32<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/moe_gru/moe_gru_round_5_scaffold_sr.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # === SINGLE global model, weights, c, and all clients use it ===\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "    # DEVICE Print\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    \n",
    "\n",
    "    server_c = [np.zeros_like(w) for w in global_weights]\n",
    "    client_cs = {cid: [np.zeros_like(w) for w in global_weights] for cid in range(NUM_CLIENTS)}\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        print(f\"Sampled {len(sampled_clients)} clients\")\n",
    "\n",
    "        local_weight_deltas = []\n",
    "        local_c_deltas = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "\n",
    "            train_loader, _ = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            delta_y, delta_c, new_ci, local_weights, fin_loss = train_model_scaffold(\n",
    "                local_model, train_loader,\n",
    "                global_weights = global_weights,\n",
    "                server_c = server_c,\n",
    "                client_ci = client_cs[cid],\n",
    "                device = DEVICE,\n",
    "                learning_rate = LR,\n",
    "                loss_fn = None,\n",
    "                optimizer_class = optim.Adam,\n",
    "                epochs = LOCAL_EPOCHS\n",
    "            )\n",
    "\n",
    "            local_weight_deltas.append(delta_y)\n",
    "            local_c_deltas.append(delta_c)\n",
    "            client_cs[cid] = new_ci\n",
    "\n",
    "        # === Aggregate and update global weights ===\n",
    "        mean_delta_y = average_weights(local_weight_deltas)\n",
    "        SERVER_LR = 1.0  # you can tune this if needed\n",
    "\n",
    "        global_weights = [\n",
    "            gw + SERVER_LR * dy for gw, dy in zip(global_weights, mean_delta_y)\n",
    "        ]\n",
    "\n",
    "        mean_delta_c = average_weights(local_c_deltas)\n",
    "        frac = len(sampled_clients) / NUM_CLIENTS\n",
    "\n",
    "        server_c = [\n",
    "            sc + frac * dc for sc, dc in zip(server_c, mean_delta_c)\n",
    "        ]\n",
    "\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        ckpt_path = os.path.join(\"results\", model_name, f\"{model_name}_round_{rnd+1}_scaffold_sr.pt\")\n",
    "        torch.save(global_model.state_dict(), ckpt_path)\n",
    "        print(f\"Saved: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92871cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f243fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /home/user/anaconda3/envs/Priyanka/bin/python\n",
      "torch.__version__: 2.6.0.dev20241112\n",
      "torch.version.cuda: None\n",
      "torch.cuda.is_available(): False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"torch.__version__:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cdc6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_scaffold(\n",
    "    local_model,\n",
    "    train_loader,         # global_model, train_loader\n",
    "    global_weights,    # x\n",
    "    server_c,          # c\n",
    "    client_ci,         # cᵢ\n",
    "    device=DEVICE,\n",
    "    learning_rate= LR,\n",
    "    loss_fn=None,\n",
    "    optimizer_class=optim.Adam,\n",
    "    epochs= LOCAL_EPOCHS  # 50\n",
    "):\n",
    "    \"\"\"Train client with SCAFFOLD correction. Return Δy, Δc, new cᵢ, final weights.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # print(f\"[DEBUG] Training on: {device}\")\n",
    "\n",
    "    \n",
    "    local_model.to(device)\n",
    "    loss_fn = loss_fn or nn.MSELoss()\n",
    "    optimizer = optimizer_class(local_model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    local_model.train()\n",
    "    total_steps = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            if y_batch.dim() == 3 and y_batch.shape[-1] == 1:\n",
    "                y_batch = y_batch.squeeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = local_model(X_batch)\n",
    "            loss = loss_fn(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ✅ SCAFFOLD correction: adjust each param after normal SGD step  # doubt at this step\n",
    "            with torch.no_grad():\n",
    "                for p, sc_np, ci_np in zip(local_model.parameters(), server_c, client_ci):\n",
    "                    sc_tensor = torch.tensor(sc_np, dtype=p.dtype, device=p.device)\n",
    "                    ci_tensor = torch.tensor(ci_np, dtype=p.dtype, device=p.device)\n",
    "                    p -= learning_rate * (sc_tensor - ci_tensor)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total_steps += 1\n",
    "        \n",
    "        loss_history.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    # Compute deltas\n",
    "    local_weights = get_weights(local_model)\n",
    "    delta_y = [lw - gw for lw, gw in zip(local_weights, global_weights)]\n",
    "\n",
    "    # K = total_steps\n",
    "    K = total_steps\n",
    "    new_ci = []\n",
    "    delta_c = []\n",
    "\n",
    "    for gw, lw, ci, sc in zip(global_weights, local_weights, client_ci, server_c):\n",
    "        ci_new = ci - sc + (gw - lw) / (K * learning_rate)\n",
    "        new_ci.append(ci_new)  # doubt can overide new_ci\n",
    "        delta_c.append(ci_new - ci)\n",
    "\n",
    "    return delta_y, delta_c, new_ci, local_weights, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b738bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /home/user/anaconda3/envs/Priyanka/bin/python\n",
      "torch.__version__: 2.6.0.dev20241112\n",
      "torch.version.cuda: None\n",
      "torch.cuda.is_available(): False\n"
     ]
    }
   ],
   "source": [
    "# print(f\"[DEBUG] Training on: {device}\")\n",
    "import sys\n",
    "import torch\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"torch.__version__:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d203077",
   "metadata": {},
   "source": [
    "## Cluster Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92175c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments for model: lstm\n",
      "\\Round 1/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:44<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [02:56<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:52<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:14<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 2/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:51<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [03:05<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:57<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 3/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:51<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [03:00<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:54<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:16<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 4/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:52<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [03:00<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:58<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:17<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 5/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:50<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [03:01<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:57<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:14<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 6/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [03:51<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [03:02<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [01:54<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [01:15<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Round 7/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0:  61%|██████▏   | 49/80 [02:26<01:33,  3.02s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Main experiment loop\n",
    "# for model_name in MODEL_NAMES:\n",
    "#     print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "#     # Initialize per-cluster model weights\n",
    "#     cluster_models = {}\n",
    "#     cluster_weights = {}\n",
    "#     global_c = {}\n",
    "#     client_cs = {}\n",
    "\n",
    "#     for cluster_name in CLUSTERS:\n",
    "#         model = model_fn(model_name).to(DEVICE) # model_fn returns batch_size, output_size\n",
    "#         # create one model per cluster and store its initial weights\n",
    "#         # model = model_fn(model_name)\n",
    "#         # print(\"[DEBUG] model_fn output:\", model)\n",
    "#         # print(\"[DEBUG] type(model_fn output):\", type(model))\n",
    "#         # model.to(DEVICE)\n",
    "#         cluster_models[cluster_name] = model\n",
    "#         cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "#         # Initialize c_i for each cluster\n",
    "#         global_c[cluster_name] = [np.zeros_like(p) for p in cluster_weights[cluster_name]]\n",
    "#         # client_cs[cluster_name] = {cid: [torch.zeros_like(p) for p in cluster_weights[cluster_name]] for cid in CLUSTERS[cluster_name]}\n",
    "#         for cid in CLUSTERS[cluster_name]:\n",
    "#             client_cs[cid] = [np.zeros_like(p) for p in cluster_weights[cluster_name]]\n",
    "\n",
    "#     for rnd in range(NUM_ROUNDS):\n",
    "#         print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "#         for cluster_name, client_ids in CLUSTERS.items():  # howw random clients id ? selection\n",
    "#             print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "#             # Sample a fraction of clients from the cluster\n",
    "#             sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "#             print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "#             local_weight_deltas = []\n",
    "#             local_c_deltas = [] # Store local c_i deltas for each client\n",
    "\n",
    "#             for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "#                 local_model = model_fn(model_name).to(DEVICE) # batch_size, output_size not this its Pythorch object an instance of nn.Module\n",
    "#                 set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "#                 train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "#                 # updated_weights, fin_loss = train_model_scaffold(\n",
    "#                 #     local_model, train_loader,\n",
    "#                 #     device=DEVICE,\n",
    "#                 #     learning_rate=LR,\n",
    "#                 #     loss_fn=None,\n",
    "#                 #     optimizer_class=optim.Adam,\n",
    "#                 #     epochs=LOCAL_EPOCHS\n",
    "#                 # )\n",
    "#                 #Local SCAFFOLD training\n",
    "#                 delta_y, delta_c, new_ci, local_weights, fin_loss = train_model_scaffold(\n",
    "#                     local_model, train_loader,\n",
    "#                     global_weights = cluster_weights[cluster_name],  # \n",
    "#                     device=DEVICE,\n",
    "#                     learning_rate=LR,\n",
    "#                     loss_fn=None,\n",
    "#                     optimizer_class=optim.Adam,\n",
    "#                     epochs=LOCAL_EPOCHS,\n",
    "#                     server_c =global_c[cluster_name],\n",
    "#                     client_ci=client_cs[cid]\n",
    "#                 )\n",
    "\n",
    "\n",
    "#                 # local_weights.append(updated_weights)\n",
    "#                 local_weight_deltas.append(delta_y)\n",
    "#                 # Update client c_i\n",
    "#                 client_cs[cid] = new_ci  # Update c_i for this client\n",
    "#                 local_c_deltas.append(delta_c)  # Store local c_i deltas for each client)\n",
    "\n",
    "#             # Aggregate and update cluster model\n",
    "#             mean_delta_y = average_weights(local_weight_deltas)\n",
    "#             SERVER_LR = 1.0  # or tune this!\n",
    "\n",
    "#             updated_cluster_weights = [\n",
    "#                 gw + SERVER_LR * dy for gw, dy in zip(cluster_weights[cluster_name], mean_delta_y)\n",
    "#             ]\n",
    "\n",
    "#             # set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "#             # updated_cluster_weights = average_weights(local_weights)\n",
    "#             set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "#             cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "#             mean_delta_c = average_weights(local_c_deltas, client_weights=None)\n",
    "\n",
    "#             cluster_size = len(client_ids)\n",
    "#             frac = len(sampled_clients) / cluster_size \n",
    "\n",
    "#             # Update global c for the cluster\n",
    "#             global_c[cluster_name] = [\n",
    "#                 gc + frac * dc for gc, dc in zip(global_c[cluster_name], mean_delta_c) \n",
    "#             ]\n",
    "\n",
    "\n",
    "#             # Save checkpoint\n",
    "#             ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}_scaffold.pt\")\n",
    "#             torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "#             # torch.save({\n",
    "#             #     'model_state': cluster_models[cluster_name].state_dict(),\n",
    "#             #     'global_c': global_c[cluster_name],\n",
    "#             #     'client_cs': {cid: client_cs[cid] for cid in client_ids}  \n",
    "#             # }, ckpt_path)\n",
    "#             # print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Config\n",
    "# # List of models to experiment with\n",
    "# MODEL_NAMES = [\"moe_gru\"]\n",
    "\n",
    "# # Config\n",
    "# NUM_CLIENTS = 1410\n",
    "# CLIENT_FRAC = 0.15\n",
    "# NUM_ROUNDS = 10\n",
    "# LOCAL_EPOCHS = 10\n",
    "# LR = 0.001\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DATA_FILE =\"train_final.feather\" # \"meter_0_data_cleaned.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ae928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments for model: moe_gru\n",
      "\\Round 1/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:45<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_1_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:36<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_1_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_1_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:14<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_1_scaff.pt\n",
      "\\Round 2/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:46<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_2_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_2_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_2_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_2_scaff.pt\n",
      "\\Round 3/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:47<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_3_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:36<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_3_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_3_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_3_scaff.pt\n",
      "\\Round 4/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:46<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_4_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_4_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_4_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_4_scaff.pt\n",
      "\\Round 5/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:46<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_5_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:36<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_5_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_5_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_5_scaff.pt\n",
      "\\Round 6/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:47<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_6_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_6_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_6_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:16<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_6_scaff.pt\n",
      "\\Round 7/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:48<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_7_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_7_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_7_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_7_scaff.pt\n",
      "\\Round 8/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:48<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_8_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_8_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_8_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_8_scaff.pt\n",
      "\\Round 9/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:47<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_9_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_9_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_9_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:16<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_9_scaff.pt\n",
      "\\Round 10/10\n",
      " Processing cluster_0 with 537 clients\n",
      "Sampling 80 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|██████████| 80/80 [00:48<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_10_scaff.pt\n",
      " Processing other with 428 clients\n",
      "Sampling 64 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training other: 100%|██████████| 64/64 [00:38<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/other/moe_gru_other_round_10_scaff.pt\n",
      " Processing cluster_1 with 269 clients\n",
      "Sampling 40 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|██████████| 40/40 [00:23<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_10_scaff.pt\n",
      " Processing cluster_2 with 179 clients\n",
      "Sampling 26 Clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|██████████| 26/26 [00:15<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_10_scaff.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Main experiment loop\n",
    "# for model_name in MODEL_NAMES:\n",
    "#     print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "#     # Initialize per-cluster model weights\n",
    "#     cluster_models = {}\n",
    "#     cluster_weights = {}\n",
    "#     global_c = {}\n",
    "#     client_cs = {}\n",
    "\n",
    "#     for cluster_name in CLUSTERS:\n",
    "#         model = model_fn(model_name).to(DEVICE) # model_fn returns batch_size, output_size\n",
    "#         # create one model per cluster and store its initial weights\n",
    "#         cluster_models[cluster_name] = model\n",
    "#         cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "#         # Initialize c_i for each cluster\n",
    "#         global_c[cluster_name] = [np.zeros_like(p) for p in cluster_weights[cluster_name]]\n",
    "#         # client_cs[cluster_name] = {cid: [torch.zeros_like(p) for p in cluster_weights[cluster_name]] for cid in CLUSTERS[cluster_name]}\n",
    "#         for cid in CLUSTERS[cluster_name]:\n",
    "#             client_cs[cid] = [np.zeros_like(p) for p in cluster_weights[cluster_name]]\n",
    "\n",
    "#     for rnd in range(NUM_ROUNDS):\n",
    "#         print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "#         for cluster_name, client_ids in CLUSTERS.items():  # howw random clients id ? selection\n",
    "#             print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "#             # Sample a fraction of clients from the cluster\n",
    "#             sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "#             print(f\"Sampling {len(sampled_clients)} Clients\")\n",
    "#             local_weight_deltas = []\n",
    "#             local_c_deltas = [] # Store local c_i deltas for each client\n",
    "\n",
    "#             for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "#                 local_model = model_fn(model_name).to(DEVICE) # batch_size, output_size not this its Pythorch object an instance of nn.Module\n",
    "#                 set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "#                 train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "#                 # updated_weights, fin_loss = train_model_scaffold(\n",
    "#                 #     local_model, train_loader,\n",
    "#                 #     device=DEVICE,\n",
    "#                 #     learning_rate=LR,\n",
    "#                 #     loss_fn=None,\n",
    "#                 #     optimizer_class=optim.Adam,\n",
    "#                 #     epochs=LOCAL_EPOCHS\n",
    "#                 # )\n",
    "#                 #Local SCAFFOLD training\n",
    "#                 delta_y, delta_c, new_ci, local_weights, fin_loss = train_model_scaffold(\n",
    "#                     local_model, train_loader,\n",
    "#                     global_weights = cluster_weights[cluster_name],  # \n",
    "#                     device=DEVICE,\n",
    "#                     learning_rate=LR,\n",
    "#                     loss_fn=None,\n",
    "#                     optimizer_class=optim.Adam,\n",
    "#                     epochs=LOCAL_EPOCHS,\n",
    "#                     server_c =global_c[cluster_name],\n",
    "#                     client_ci=client_cs[cid]\n",
    "#                 )\n",
    "\n",
    "\n",
    "#                 # local_weights.append(updated_weights)\n",
    "#                 local_weight_deltas.append(delta_y)\n",
    "#                 # Update client c_i\n",
    "#                 client_cs[cid] = new_ci  # Update c_i for this client\n",
    "#                 local_c_deltas.append(delta_c)  # Store local c_i deltas for each client)\n",
    "\n",
    "#             # Aggregate and update cluster model\n",
    "#             mean_delta_y = average_weights(local_weight_deltas)\n",
    "#             SERVER_LR = 1.0  # or tune this!\n",
    "\n",
    "#             updated_cluster_weights = [\n",
    "#                 gw + SERVER_LR * dy for gw, dy in zip(cluster_weights[cluster_name], mean_delta_y)\n",
    "#             ]\n",
    "\n",
    "#             # set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "#             # updated_cluster_weights = average_weights(local_weights)\n",
    "#             set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "#             cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "#             mean_delta_c = average_weights(local_c_deltas, client_weights=None)\n",
    "\n",
    "#             cluster_size = len(client_ids)\n",
    "#             frac = len(sampled_clients) / cluster_size \n",
    "\n",
    "#             # Update global c for the cluster\n",
    "#             global_c[cluster_name] = [\n",
    "#                 gc + frac * dc for gc, dc in zip(global_c[cluster_name], mean_delta_c) \n",
    "#             ]\n",
    "\n",
    "\n",
    "#             # Save checkpoint\n",
    "#             ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}_scaff.pt\")\n",
    "#             # torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "#             torch.save({\n",
    "#                 'model_state': cluster_models[cluster_name].state_dict(),\n",
    "#                 'global_c': global_c[cluster_name],\n",
    "#                 'client_cs': {cid: client_cs[cid] for cid in client_ids}  \n",
    "#             }, ckpt_path)\n",
    "#             print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"lstm\"  # or any other model you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb3f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e8cc8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
