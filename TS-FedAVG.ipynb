{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c26839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/flower/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d0695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AggregationStrategy import sync_aggregate,average_weights,sync_aggregate_norm,sync_aggregate_softmax, fedavgm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57bad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_weights(weights_list):\n",
    "#     \"\"\"Averages model weights provided as a list of get_weights outputs.\"\"\"\n",
    "#     avg_weights = []\n",
    "#     num_models = len(weights_list)\n",
    "#     for layer_weights in zip(*weights_list):\n",
    "#         avg_layer = np.mean(np.array(layer_weights), axis=0)\n",
    "#         avg_weights.append(avg_layer)\n",
    "#     return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5872d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04da54ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad6e28",
   "metadata": {},
   "source": [
    "### Clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define your clusters manually (or randomly for now)\n",
    "CLUSTERS = {\n",
    "    \"cluster_0\": list(range(0, 30)),    # Clients 0‚Äì29\n",
    "    \"cluster_1\": list(range(30, 60)),   # Clients 30‚Äì59\n",
    "    \"cluster_2\": list(range(60, 90)),   # Clients 60‚Äì89\n",
    "}\n",
    "\n",
    "# Create results directory\n",
    "for model_name in MODEL_NAMES:\n",
    "    for cluster_name in CLUSTERS:\n",
    "        os.makedirs(os.path.join(\"results\", model_name, cluster_name), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Starting experiments for model: lstm\n",
      "\n",
      "üåÄ Round 1/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_1.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_1.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_1.pt\n",
      "\n",
      "üåÄ Round 2/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_2.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_2.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_2.pt\n",
      "\n",
      "üåÄ Round 3/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_3.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_3.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_3.pt\n",
      "\n",
      "üåÄ Round 4/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_4.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_4.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_4.pt\n",
      "\n",
      "üåÄ Round 5/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_5.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_5.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_5.pt\n",
      "\n",
      "üåÄ Round 6/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_6.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_6.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_6.pt\n",
      "\n",
      "üåÄ Round 7/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_7.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_7.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_7.pt\n",
      "\n",
      "üåÄ Round 8/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_8.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_8.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_8.pt\n",
      "\n",
      "üåÄ Round 9/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_9.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_9.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_9.pt\n",
      "\n",
      "üåÄ Round 10/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_0/lstm_cluster_0_round_10.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_1/lstm_cluster_1_round_10.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/lstm/cluster_2/lstm_cluster_2_round_10.pt\n",
      "\n",
      "üåê Starting experiments for model: gru\n",
      "\n",
      "üåÄ Round 1/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_1.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_1.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_1.pt\n",
      "\n",
      "üåÄ Round 2/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_2.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_2.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_2.pt\n",
      "\n",
      "üåÄ Round 3/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_3.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_3.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_3.pt\n",
      "\n",
      "üåÄ Round 4/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_4.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_4.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_4.pt\n",
      "\n",
      "üåÄ Round 5/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_5.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_5.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_5.pt\n",
      "\n",
      "üåÄ Round 6/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_6.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_6.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_6.pt\n",
      "\n",
      "üåÄ Round 7/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_7.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_7.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_7.pt\n",
      "\n",
      "üåÄ Round 8/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_8.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_8.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_8.pt\n",
      "\n",
      "üåÄ Round 9/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_9.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_9.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_9.pt\n",
      "\n",
      "üåÄ Round 10/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_0/gru_cluster_0_round_10.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_1/gru_cluster_1_round_10.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/gru/cluster_2/gru_cluster_2_round_10.pt\n",
      "\n",
      "üåê Starting experiments for model: moe_lstm\n",
      "\n",
      "üåÄ Round 1/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_1.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_1.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_1.pt\n",
      "\n",
      "üåÄ Round 2/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_2.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_2.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_2.pt\n",
      "\n",
      "üåÄ Round 3/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_3.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_3.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_3.pt\n",
      "\n",
      "üåÄ Round 4/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_4.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_4.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_4.pt\n",
      "\n",
      "üåÄ Round 5/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_5.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_5.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_5.pt\n",
      "\n",
      "üåÄ Round 6/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_6.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_6.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_6.pt\n",
      "\n",
      "üåÄ Round 7/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_7.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_7.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_7.pt\n",
      "\n",
      "üåÄ Round 8/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_8.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_8.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_8.pt\n",
      "\n",
      "üåÄ Round 9/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_9.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_9.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_9.pt\n",
      "\n",
      "üåÄ Round 10/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_0/moe_lstm_cluster_0_round_10.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_1/moe_lstm_cluster_1_round_10.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_lstm/cluster_2/moe_lstm_cluster_2_round_10.pt\n",
      "\n",
      "üåê Starting experiments for model: moe_gru\n",
      "\n",
      "üåÄ Round 1/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_1.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_1.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_1.pt\n",
      "\n",
      "üåÄ Round 2/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_2.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_2.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_2.pt\n",
      "\n",
      "üåÄ Round 3/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_3.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_3.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_3.pt\n",
      "\n",
      "üåÄ Round 4/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_4.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_4.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_4.pt\n",
      "\n",
      "üåÄ Round 5/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_5.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_5.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_5.pt\n",
      "\n",
      "üåÄ Round 6/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_6.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_6.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_6.pt\n",
      "\n",
      "üåÄ Round 7/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_7.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_7.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_7.pt\n",
      "\n",
      "üåÄ Round 8/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_8.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_8.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_8.pt\n",
      "\n",
      "üåÄ Round 9/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_9.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_9.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_9.pt\n",
      "\n",
      "üåÄ Round 10/10\n",
      "üîπ Processing cluster_0 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_0/moe_gru_cluster_0_round_10.pt\n",
      "üîπ Processing cluster_1 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_1/moe_gru_cluster_1_round_10.pt\n",
      "üîπ Processing cluster_2 with 30 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cluster_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model: results/moe_gru/cluster_2/moe_gru_cluster_2_round_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiments for model: {model_name}\")\n",
    "\n",
    "    # Initialize per-cluster model weights\n",
    "    cluster_models = {}\n",
    "    cluster_weights = {}\n",
    "\n",
    "    for cluster_name in CLUSTERS:\n",
    "        model = model_fn(model_name).to(DEVICE)\n",
    "        cluster_models[cluster_name] = model\n",
    "        cluster_weights[cluster_name] = get_weights(model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"\\Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "\n",
    "        for cluster_name, client_ids in CLUSTERS.items():\n",
    "            print(f\" Processing {cluster_name} with {len(client_ids)} clients\")\n",
    "\n",
    "            # Sample a fraction of clients from the cluster\n",
    "            sampled_clients = random.sample(client_ids, k=int(CLIENT_FRAC * len(client_ids)))\n",
    "            local_weights = []\n",
    "\n",
    "            for cid in tqdm(sampled_clients, desc=f\"Training {cluster_name}\"):\n",
    "                local_model = model_fn(model_name).to(DEVICE)\n",
    "                set_weights(local_model, cluster_weights[cluster_name])\n",
    "\n",
    "                train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "                updated_weights, fin_loss = train_model(\n",
    "                    local_model, train_loader,\n",
    "                    device=DEVICE,\n",
    "                    learning_rate=LR,\n",
    "                    loss_fn=None,\n",
    "                    optimizer_class=optim.Adam,\n",
    "                    epochs=LOCAL_EPOCHS\n",
    "                )\n",
    "                local_weights.append(updated_weights)\n",
    "\n",
    "            # Aggregate and update cluster model\n",
    "            updated_cluster_weights = average_weights(local_weights)\n",
    "            set_weights(cluster_models[cluster_name], updated_cluster_weights)\n",
    "            cluster_weights[cluster_name] = updated_cluster_weights\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_path = os.path.join(\"results\", model_name, cluster_name, f\"{model_name}_{cluster_name}_round_{rnd+1}.pt\")\n",
    "            torch.save(cluster_models[cluster_name].state_dict(), ckpt_path)\n",
    "            print(f\"Saved model: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e2e5e",
   "metadata": {},
   "source": [
    "### FedAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a335fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:48<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_1_fedAvg.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:47<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_2_fedAvg.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:48<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_3_fedAvg.pt\n",
      "Round 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:48<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_4_fedAvg.pt\n",
      "Round 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:47<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results/lstm/lstm_round_5_fedAvg.pt\n",
      "Round 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 145/150 [00:46<00:01,  2.96it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = average_weights(local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvg.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e44db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a8a8d1",
   "metadata": {},
   "source": [
    "### FedAvgM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6693f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:42<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global model to results\\lstm\\lstm_round_1_kr_norm.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  40%|‚ñà‚ñà‚ñà‚ñà      | 6/15 [00:20<00:30,  3.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     set_weights(local_model, global_weights)\n\u001b[0;32m     35\u001b[0m     train_loader, test_loader \u001b[38;5;241m=\u001b[39m load_energy_data_feather(cid, filepath\u001b[38;5;241m=\u001b[39mDATA_FILE)\n\u001b[1;32m---> 37\u001b[0m     updated_weights, fin_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_EPOCHS\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Federated averaging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\my_utils.py:103\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, device, learning_rate, loss_fn, optimizer_class, epochs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    102\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 103\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y_batch)\n\u001b[0;32m    105\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\Models.py:136\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# x: shape (batch, time, input_features)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m            \u001b[38;5;66;03m# out: (batch, time, hidden_size)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]              \u001b[38;5;66;03m# Take last time step output: (batch, hidden_size)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)               \u001b[38;5;66;03m# Final output: (batch, output_size)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    velocity = [np.zeros_like(w) for w in global_weights]\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights, velocity = fedavgm_update(global_weights,local_weights,velocity)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_fedAvgM.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9d5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d7749f",
   "metadata": {},
   "source": [
    "### Kuramoto FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e051a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30767af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b81983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_norm(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_norm.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# List of models to experiment with\n",
    "MODEL_NAMES = [\"lstm\", \"gru\", \"moe_lstm\", \"moe_gru\"]\n",
    "\n",
    "# Config\n",
    "NUM_CLIENTS = 1000\n",
    "CLIENT_FRAC = 0.15\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 10\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_FILE =\"train_cleaned_reindex.feather\" # \"meter_0_data_cleaned.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aeb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with model: lstm\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:16<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC Weights:[1.1280927881409405e-24, 3.455221414490252e-24, 2.7815943992592906e-10, 1.5342428063772783e-20, 8.519412258989334e-11, 1.0, 4.7079616409486216e-23, 0.0, 0.0, 1.4587423713408043e-08] \n",
      "Saved global model to results\\lstm\\lstm_round_1_kr.pt\n",
      "Round 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:16<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC Weights:[0.051666800892013795, 2.0060822225145682e-07, 0.0038842655760772567, 0.33163288880904007, 0.05313184572821639, 0.17136356681197534, 4.1494413146093236e-12, 2.694967957872787e-05, 0.3882710659981862, 2.2412009829798056e-05] \n",
      "Saved global model to results\\lstm\\lstm_round_2_kr.pt\n",
      "Round 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:19<00:46,  6.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     set_weights(local_model, global_weights)\n\u001b[0;32m     33\u001b[0m     train_loader, test_loader \u001b[38;5;241m=\u001b[39m load_energy_data_feather(cid, filepath\u001b[38;5;241m=\u001b[39mDATA_FILE)\n\u001b[1;32m---> 35\u001b[0m     updated_weights, fin_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_EPOCHS\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Federated averaging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\my_utils.py:105\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, device, learning_rate, loss_fn, optimizer_class, epochs)\u001b[0m\n\u001b[0;32m    103\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m    104\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y_batch)\n\u001b[1;32m--> 105\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    108\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\srina\\OneDrive\\Documents\\Federated Learning - Priyanka\\Diffusion_FL\\energy-ts-diffusion\\darts\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# # Weighted averaging function (uniform weights for now)\n",
    "# def average_weights(weights_list):\n",
    "#     return [np.mean(np.stack(layer_weights), axis=0) for layer_weights in zip(*weights_list)]\n",
    "\n",
    "# Make sure your model_fn is already defined as in your message\n",
    "\n",
    "# Main experiment loop\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"Starting experiment with model: {model_name}\")\n",
    "\n",
    "    # Directory to save checkpoints\n",
    "    model_dir = os.path.join(\"results\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Init model and weights\n",
    "    global_model = model_fn(model_name).to(DEVICE)\n",
    "    global_weights = get_weights(global_model)\n",
    "\n",
    "    for rnd in range(NUM_ROUNDS):\n",
    "        print(f\"Round {rnd+1}/{NUM_ROUNDS}\")\n",
    "        sampled_clients = random.sample(range(NUM_CLIENTS), k=int(CLIENT_FRAC * NUM_CLIENTS))\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in tqdm(sampled_clients, desc=\"Training clients\"):\n",
    "            local_model = model_fn(model_name).to(DEVICE)\n",
    "            set_weights(local_model, global_weights)\n",
    "            train_loader, test_loader = load_energy_data_feather(cid, filepath=DATA_FILE)\n",
    "\n",
    "            updated_weights, fin_loss = train_model(\n",
    "                local_model, train_loader,\n",
    "                device=DEVICE,\n",
    "                learning_rate=LR,\n",
    "                loss_fn=None,\n",
    "                optimizer_class=optim.Adam,\n",
    "                epochs=LOCAL_EPOCHS\n",
    "            )\n",
    "            local_weights.append(updated_weights)\n",
    "\n",
    "        # Federated averaging\n",
    "        global_weights = sync_aggregate_softmax(global_weights,local_weights)\n",
    "        set_weights(global_model, global_weights)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(model_dir, f\"{model_name}_round_{rnd+1}_kr_sft.pt\")\n",
    "        torch.save(global_model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved global model to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371dc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef1b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8f050b",
   "metadata": {},
   "source": [
    "### Diff-Aware Fed Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908746a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314b5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd808c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d94ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4d069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25059312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb3980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc2201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a69607",
   "metadata": {},
   "source": [
    "### Diff-Sync FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bac448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29066235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65a8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0e8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b006b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e8cc8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
