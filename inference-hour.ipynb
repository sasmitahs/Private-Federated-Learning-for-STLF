{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1518ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/flower/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n",
    "from energy_ts_diffusion.task import convert_timeseries_to_numpy  # adjust as per your project\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06b21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def rolling_forecast_on_test_hourly(cid, model, filepath=\"train_final.feather\", input_len=24, output_len=8):\n",
    "    \"\"\"\n",
    "    Perform rolling window forecast using a model trained with hour-aware input.\n",
    "    Returns unscaled predictions and ground truths with actual timestamps.\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] rolling_forecast_on_test_hourly: CID={cid}\")\n",
    "\n",
    "\n",
    "    # Load and filter data\n",
    "    df = pd.read_feather(filepath)\n",
    "    df = df[df['building_id'] == cid]\n",
    "    df['meter_reading'] = df['meter_reading'].fillna(0)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found for building_id {cid}\")\n",
    "\n",
    "    # Extract hour of day and normalize to [0, 1]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['hour'] = df['timestamp'].dt.hour / 23.0\n",
    "\n",
    "    # Create TimeSeries with both meter + hour\n",
    "    ts = TimeSeries.from_dataframe(\n",
    "        df,\n",
    "        time_col='timestamp',\n",
    "        value_cols=['meter_reading', 'hour'],\n",
    "        fill_missing_dates=True,\n",
    "        freq='h'\n",
    "    )\n",
    "\n",
    "    _, test_series = ts.split_before(0.75)\n",
    "\n",
    "    # Scale both features\n",
    "    scaler = MinMaxScaler(feature_range=(0.1, 1))\n",
    "    transformer = Scaler(scaler)\n",
    "    test_series_scaled = transformer.fit_transform(test_series)\n",
    "\n",
    "    test_values_scaled = test_series_scaled.values()  # shape: [T, 2]\n",
    "    test_timestamps = test_series_scaled.time_index\n",
    "\n",
    "    predictions_ts_list = []\n",
    "    ground_truth_ts_list = []\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for i in range(0, len(test_values_scaled) - input_len - output_len + 1):\n",
    "        input_seq = test_values_scaled[i:i+input_len]             # [24, 2]\n",
    "        true_output = test_values_scaled[i+input_len:i+input_len+output_len, 0]  # only meter_reading\n",
    "        true_time = test_timestamps[i+input_len:i+input_len+output_len]\n",
    "\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)  # [1, 24, 2]\n",
    "\n",
    "        pred = model(input_tensor)  # [1, 8] or [1, 8, 1]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.squeeze(0).squeeze(-1)\n",
    "        else:\n",
    "            pred = pred.squeeze(0)\n",
    "\n",
    "        # Wrap predictions and ground truth in TimeSeries\n",
    "        # Pad pred with dummy hour feature (e.g., zeros) for inverse transform\n",
    "        dummy_hours = np.zeros_like(pred.cpu().numpy())\n",
    "        pred_padded = np.stack([pred.cpu().numpy(), dummy_hours], axis=-1)\n",
    "        true_padded = np.stack([true_output, dummy_hours], axis=-1)\n",
    "\n",
    "        # Convert to TimeSeries\n",
    "        pred_ts = TimeSeries.from_times_and_values(true_time, pred_padded)\n",
    "        true_ts = TimeSeries.from_times_and_values(true_time, true_padded)\n",
    "\n",
    "        # Inverse transform\n",
    "        pred_unscaled = transformer.inverse_transform(pred_ts).values()[:, 0]\n",
    "        true_unscaled = transformer.inverse_transform(true_ts).values()[:, 0]\n",
    "\n",
    "        # Save as TimeSeries\n",
    "        pred_ts = TimeSeries.from_times_and_values(true_time, pred_unscaled)\n",
    "        true_ts = TimeSeries.from_times_and_values(true_time, true_unscaled)\n",
    "\n",
    "\n",
    "        predictions_ts_list.append(pred_ts)\n",
    "        ground_truth_ts_list.append(true_ts)\n",
    "\n",
    "    return predictions_ts_list, ground_truth_ts_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2ddc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions_csv(model_name: str, cid: int, aggr_strat: str, rounds: list, model_dir: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    For each round, load the model, predict on test set for cid, and save all preds in a single CSV.\n",
    "    Uses the hour-aware rolling forecast.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for rnd in tqdm(rounds):\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_round_{rnd}_{aggr_strat}.pt\")\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"[WARN] Model not found: {model_path}\")\n",
    "            continue\n",
    "\n",
    "        model = model_fn(model_name)\n",
    "        state_dict = torch.load(model_path, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to('cuda')\n",
    "        model.eval()\n",
    "\n",
    "        # ðŸ” Use hour-aware rolling forecast\n",
    "        pred_ts_list, gt_ts_list = rolling_forecast_on_test_hourly(cid=cid, model=model)\n",
    "\n",
    "        for pred_ts, true_ts in zip(pred_ts_list, gt_ts_list):\n",
    "            df_pred = pd.DataFrame({\"timestamp\": pred_ts.time_index, \"pred\": pred_ts.values().squeeze()})\n",
    "            df_true = pd.DataFrame({\"timestamp\": true_ts.time_index, \"true\": true_ts.values().squeeze()})\n",
    "\n",
    "            df_merged = pd.merge(df_true, df_pred, on=\"timestamp\", how=\"inner\")\n",
    "            df_merged[\"round\"] = rnd\n",
    "\n",
    "            rows.append(df_merged[[\"timestamp\", \"true\", \"pred\", \"round\"]])\n",
    "\n",
    "    if rows:\n",
    "        final_df = pd.concat(rows, ignore_index=True)\n",
    "        final_df.to_csv(output_csv, index=False)\n",
    "        print(f\"[INFO] Forecasts written to {output_csv}\")\n",
    "    else:\n",
    "        print(\"[WARN] No predictions made â€” check if models exist or round list is valid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fe58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_strategy_csv(Base_dir, Target_dir, round_num, METRIC, sortBy=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Computes boxplot statistics for each model_strategy CSV\n",
    "    and saves the pivot table in the target directory.\n",
    "\n",
    "    The metric column is dynamically named with METRIC.\n",
    "    \"\"\"\n",
    "    os.makedirs(Target_dir, exist_ok=True)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for csv_file in os.listdir(Base_dir):\n",
    "        if not csv_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(Base_dir, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the specified round\n",
    "        df_round = df[df[\"round\"] == round_num]\n",
    "\n",
    "        if df_round.empty:\n",
    "            print(f\"[SKIP] No round {round_num} in: {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        metric_values = df_round[METRIC].dropna()\n",
    "\n",
    "        # Compute stats\n",
    "        count = metric_values.count()\n",
    "        min_val = metric_values.min()\n",
    "        q1 = metric_values.quantile(0.25)\n",
    "        median = metric_values.median()\n",
    "        q3 = metric_values.quantile(0.75)\n",
    "        max_val = metric_values.max()\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Whiskers\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "\n",
    "        # Non-outlier min/max\n",
    "        non_outliers = metric_values[(metric_values >= lower_whisker) & (metric_values <= upper_whisker)]\n",
    "        min_non_outlier = non_outliers.min()\n",
    "        max_non_outlier = non_outliers.max()\n",
    "\n",
    "        # Extract model_strategy and strategy\n",
    "        model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "        try:\n",
    "            model, strategy = model_strategy.split(\"_\", 1)\n",
    "        except ValueError:\n",
    "            strategy = \"unknown\"\n",
    "\n",
    "        # âœ… The metric name is now a column with the median value.\n",
    "        row = {\n",
    "            \"Model_Strategy\": model_strategy,\n",
    "            # \"Strategy\": strategy,\n",
    "            \"Round\": round_num,\n",
    "            \"METRIC\": METRIC,  # dynamic metric column with value\n",
    "            \"Count\": count,\n",
    "            \"Min\": min_val,\n",
    "            \"Q1\": q1,\n",
    "            \"Median\": median,\n",
    "            \"Q3\": q3,\n",
    "            \"Max\": max_val,\n",
    "            \"IQR\": iqr,\n",
    "            # \"Lower Whisker\": lower_whisker,\n",
    "            # \"Upper Whisker\": upper_whisker,\n",
    "            \"True Min (Non-outlier)\": min_non_outlier,\n",
    "            \"True Max (Non-outlier)\": max_non_outlier\n",
    "        }\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    # Combine to DataFrame\n",
    "    pivot_df = pd.DataFrame(all_rows)\n",
    "    pivot_df.sort_values(by=sortBy, inplace=True)\n",
    "\n",
    "    # Clean output name\n",
    "    safe_metric = METRIC.replace(\" \", \"_\").replace(\"%\", \"percent\")\n",
    "    pivot_output = os.path.join(\n",
    "        Target_dir,\n",
    "        f\"all_stats_round{round_num}_metric_{safe_metric}_sort_by_{sortBy}.csv\"\n",
    "    )\n",
    "\n",
    "    pivot_df.to_csv(pivot_output, index=False)\n",
    "\n",
    "    print(f\"[OK] One-row-per-model_strategy pivot saved: {pivot_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e13744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate forecasts - working correctly 1411 buildings count \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    return np.mean(np.where(denominator == 0, 0, np.abs(y_true - y_pred) / denominator)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error.\"\"\"\n",
    "    y_true = np.where(y_true == 0, 1e-8, y_true)  # avoid division by zero\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def evaluate_forecast_metrics_per_round(csv_path):\n",
    "    \"\"\"\n",
    "    Reads forecast CSV and computes MAPE, MAE, SMAPE, RMSE, and MSE per round.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV with columns: timestamp, true, pred, round\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Metrics summary per round\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"CSV is empty or invalid\")\n",
    "\n",
    "    metrics_list = []\n",
    "\n",
    "    for rnd in sorted(df['round'].unique()):\n",
    "\n",
    "        df_rnd = df[df['round'] == rnd]\n",
    "        df_rnd = df_rnd.fillna(0.005)\n",
    "        y_true = df_rnd[\"true\"].values\n",
    "        y_pred = df_rnd[\"pred\"].values\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape_val = mape(y_true, y_pred)\n",
    "        smape_val = smape(y_true, y_pred)\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"round\": rnd,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE (%)\": mape_val,\n",
    "            \"SMAPE (%)\": smape_val\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72361cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the model_strategy_csv of round 10 ,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d144020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try in function\n",
    "def get_model_metric_grouped_by_model_strategy(\n",
    "    MODELS: List[str],\n",
    "    STRATEGIES: List[str],\n",
    "    ROUNDS: List[int],\n",
    "    BASE_PREDICTIONS_DIR: str,\n",
    "    BASE_METRICS_DIR: str,\n",
    "    METRIC: str = \"MAE\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    \n",
    "    Args:\n",
    "        MODELS (List[str]): List of model names.\n",
    "        STRATEGIES (List[str]): List of strategy names.\n",
    "        ROUNDS (List[int]): List of round numbers.\n",
    "        BASE_PREDICTIONS_DIR (str): Directory containing prediction CSVs.\n",
    "        BASE_METRICS_DIR (str): Directory to save metrics CSVs.\n",
    "        METRIC (str): The metric to compute, e.g., \"MAE\", \"MSE\", etc.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for CID in tqdm(range(1411), desc=\"Processing Client IDs\"):\n",
    "        for model_name in MODELS:\n",
    "            for strategy in STRATEGIES:\n",
    "                input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "                output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "                if not os.path.isfile(input_csv):\n",
    "                    print(f\"[SKIP] Missing: {input_csv}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Compute metrics for the given CSV\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "                    metrics_df.insert(0, \"building_id\", CID)  # add client ID\n",
    "                    metrics_df.insert(1, \"model\", model_name)\n",
    "                    metrics_df.insert(2, \"strategy\", strategy)\n",
    "\n",
    "                    if os.path.isfile(output_csv):\n",
    "                        metrics_df.to_csv(output_csv, index=False)\n",
    "                    else:\n",
    "                        metrics_df.to_csv(output_csv, index=False)\n",
    "\n",
    "                    print(f\"[OK] {output_csv} <- CID {CID}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c422bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b12a20e2",
   "metadata": {},
   "source": [
    "## Predicitons metric both (above code in function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c4b94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_model_predictions_metric(\n",
    "    MODELS,\n",
    "    STRATEGIES,\n",
    "    ROUNDS,\n",
    "    BASE_RESULTS_DIR: str,\n",
    "    BASE_OUTPUT_DIR: str,\n",
    "    METRICS_DIR: str,\n",
    "    CID: range\n",
    "):\n",
    "    \"\"\"\n",
    "    For each client in CID, model in MODELS, and strategy in STRATEGIES,\n",
    "    generates forecast predictions and computes metrics.\n",
    "\n",
    "    This version supports both regular and hour-aware models.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for cid in CID:\n",
    "        print(f\"\\nProcessing Client ID: {cid}\")\n",
    "\n",
    "        for model_name in MODELS:\n",
    "            for strategy in STRATEGIES:\n",
    "                model_dir = os.path.join(BASE_RESULTS_DIR, model_name)\n",
    "                output_csv = os.path.join(BASE_OUTPUT_DIR, f\"{cid}_{model_name}_{strategy}.csv\")\n",
    "                metrics_csv = os.path.join(METRICS_DIR, f\"cid{cid}_{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "                print(f\"\\n Model: {model_name}, Strategy: {strategy}\")\n",
    "\n",
    "                try:\n",
    "                    # Choose prediction function based on whether model uses hour input\n",
    "                    if \"hour\" in model_name.lower():\n",
    "                        get_model_predictions_csv(\n",
    "                            model_name=model_name,\n",
    "                            cid=cid,\n",
    "                            rounds=ROUNDS,\n",
    "                            model_dir=model_dir,\n",
    "                            output_csv=output_csv,\n",
    "                            aggr_strat=strategy\n",
    "                        )\n",
    "                    else:\n",
    "                        get_model_predictions_csv(\n",
    "                            model_name=model_name,\n",
    "                            cid=cid,\n",
    "                            rounds=ROUNDS,\n",
    "                            model_dir=model_dir,\n",
    "                            output_csv=output_csv,\n",
    "                            aggr_strat=strategy\n",
    "                        )\n",
    "\n",
    "                    # Compute metrics\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(output_csv)\n",
    "                    metrics_df.to_csv(metrics_csv, index=False)\n",
    "                    print(f\"Metrics saved to {metrics_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] model={model_name}, strategy={strategy}, cid={cid}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809a1ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Client ID: 70\n",
      "\n",
      " Model: simple_ann_hour, Strategy: fedAvg_hr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1/49 [00:01<01:35,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2/49 [00:03<01:31,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 3/49 [00:05<01:26,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/49 [00:07<01:25,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/49 [00:09<01:21,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 6/49 [00:11<01:22,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 7/49 [00:13<01:18,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 8/49 [00:15<01:17,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 9/49 [00:17<01:16,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/49 [00:18<01:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 11/49 [00:20<01:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 12/49 [00:22<01:10,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 13/49 [00:24<01:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–Š       | 14/49 [00:26<01:04,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 15/49 [00:28<01:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/49 [00:30<01:02,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 17/49 [00:32<00:59,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 18/49 [00:34<01:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 19/49 [00:36<00:57,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/49 [00:37<00:54,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 21/49 [00:39<00:51,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/49 [00:41<00:52,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 23/49 [00:43<00:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 24/49 [00:45<00:47,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/49 [00:47<00:44,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 26/49 [00:49<00:42,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 27/49 [00:51<00:43,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 28/49 [00:53<00:40,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 29/49 [00:54<00:37,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/49 [00:56<00:35,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 31/49 [00:58<00:33,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 32/49 [01:00<00:33,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 33/49 [01:02<00:30,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 34/49 [01:04<00:28,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/49 [01:06<00:25,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 36/49 [01:08<00:23,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 37/49 [01:09<00:22,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 38/49 [01:12<00:21,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 39/49 [01:13<00:19,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/49 [01:15<00:17,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 41/49 [01:17<00:14,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 42/49 [01:19<00:12,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 43/49 [01:21<00:11,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 44/49 [01:22<00:09,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/49 [01:25<00:07,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/49 [01:27<00:05,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 47/49 [01:28<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 48/49 [01:30<00:01,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [01:32<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/70_simple_ann_hour_fedAvg_hr.csv\n",
      "Metrics saved to metrics1411/cid70_simple_ann_hour_fedAvg_hr_metrics.csv\n",
      "\n",
      "Processing Client ID: 71\n",
      "\n",
      " Model: simple_ann_hour, Strategy: fedAvg_hr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1/49 [00:01<01:28,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2/49 [00:03<01:25,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 3/49 [00:05<01:22,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/49 [00:07<01:21,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/49 [00:09<01:19,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 6/49 [00:11<01:20,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 7/49 [00:12<01:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 8/49 [00:14<01:18,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 9/49 [00:16<01:16,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/49 [00:18<01:12,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 11/49 [00:20<01:14,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 12/49 [00:22<01:10,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 13/49 [00:24<01:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–Š       | 14/49 [00:26<01:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 15/49 [00:28<01:04,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/49 [00:30<01:01,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 17/49 [00:32<01:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 18/49 [00:33<00:58,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 19/49 [00:35<00:55,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/49 [00:37<00:53,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 21/49 [00:39<00:50,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/49 [00:41<00:51,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 23/49 [00:43<00:48,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 24/49 [00:44<00:46,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/49 [00:46<00:44,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 26/49 [00:49<00:45,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 27/49 [00:50<00:42,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 28/49 [00:52<00:39,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 29/49 [00:54<00:37,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/49 [00:56<00:35,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 31/49 [00:58<00:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 32/49 [01:00<00:32,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 33/49 [01:02<00:29,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 34/49 [01:03<00:27,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/49 [01:05<00:25,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 36/49 [01:07<00:23,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 37/49 [01:09<00:23,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 38/49 [01:11<00:21,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 39/49 [01:13<00:18,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/49 [01:15<00:16,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 41/49 [01:16<00:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 42/49 [01:18<00:12,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 43/49 [01:20<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 44/49 [01:22<00:09,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/49 [01:24<00:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/49 [01:26<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 47/49 [01:28<00:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 48/49 [01:30<00:01,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test_hourly: CID=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [01:31<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/71_simple_ann_hour_fedAvg_hr.csv\n",
      "Metrics saved to metrics1411/cid71_simple_ann_hour_fedAvg_hr_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [ \"fedAvg_hr\",] #\"scaffold_lr\", \"diff_lr2\",\"das11\",\"das2\",\n",
    "MODELS = [ \"simple_ann_hour\"] #,\"gru\"\n",
    "# CID = 45\n",
    "ROUNDS = list(range(1, 50))\n",
    "BASE_RESULTS_DIR = \"results\"\n",
    "BASE_OUTPUT_DIR = \"predictions1411\"\n",
    "METRICS_DIR = \"metrics1411\"\n",
    "CID = range(70,72) \n",
    "\n",
    "get_model_predictions_metric(\n",
    "    MODELS=MODELS,\n",
    "    STRATEGIES=STRATEGIES,\n",
    "    ROUNDS=ROUNDS,\n",
    "    BASE_RESULTS_DIR=BASE_RESULTS_DIR,\n",
    "    BASE_OUTPUT_DIR=BASE_OUTPUT_DIR,\n",
    "    METRICS_DIR=METRICS_DIR,\n",
    "    CID=CID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9daf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace84dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try in function\n",
    "# def get_model_metric_grouped_by_model_strategy(\n",
    "#     MODELS: List[str],\n",
    "#     STRATEGIES: List[str],\n",
    "#     ROUNDS: List[int],\n",
    "#     BASE_PREDICTIONS_DIR: str,\n",
    "#     BASE_METRICS_DIR: str,\n",
    "#     METRIC: str = \"MAE\"\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    \n",
    "#     Args:\n",
    "#         MODELS (List[str]): List of model names.\n",
    "#         STRATEGIES (List[str]): List of strategy names.\n",
    "#         ROUNDS (List[int]): List of round numbers.\n",
    "#         BASE_PREDICTIONS_DIR (str): Directory containing prediction CSVs.\n",
    "#         BASE_METRICS_DIR (str): Directory to save metrics CSVs.\n",
    "#         METRIC (str): The metric to compute, e.g., \"MAE\", \"MSE\", etc.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "#     for CID in tqdm(range(1411), desc=\"Processing Client IDs\"):\n",
    "#         for model_name in MODELS:\n",
    "#             for strategy in STRATEGIES:\n",
    "#                 input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "#                 output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "#                 if not os.path.isfile(input_csv):\n",
    "#                     print(f\"[SKIP] Missing: {input_csv}\")\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     # Compute metrics for the given CSV\n",
    "#                     metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "#                     metrics_df.insert(0, \"building_id\", CID)  # add client ID\n",
    "#                     metrics_df.insert(1, \"model\", model_name)\n",
    "#                     metrics_df.insert(2, \"strategy\", strategy)\n",
    "\n",
    "#                     if os.path.isfile(output_csv):\n",
    "#                         metrics_df.to_csv(output_csv, index=False)\n",
    "#                     else:\n",
    "#                         metrics_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"[OK] {output_csv} <- CID {CID}\")\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_model_metric_grouped_by_model_strategy(\n",
    "    MODELS: List[str],\n",
    "    STRATEGIES: List[str],\n",
    "    ROUNDS: List[int],\n",
    "    BASE_PREDICTIONS_DIR: str,\n",
    "    BASE_METRICS_DIR: str,\n",
    "    METRIC: str = \"MAE\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    Overwrites existing CSVs with combined results for all building IDs.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for model_name in MODELS:\n",
    "        for strategy in STRATEGIES:\n",
    "            all_metrics = []  # Accumulate metrics per model-strategy\n",
    "            print(f\"\\nðŸ“Š Collecting metrics: {model_name} | {strategy}\")\n",
    "\n",
    "            for CID in tqdm(range(1411), desc=f\"{model_name}_{strategy}\"):\n",
    "                input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "\n",
    "                if not os.path.isfile(input_csv):\n",
    "                    print(f\"[SKIP] Missing: {input_csv}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "                    metrics_df.insert(0, \"building_id\", CID)\n",
    "                    metrics_df.insert(1, \"model\", model_name)\n",
    "                    metrics_df.insert(2, \"strategy\", strategy)\n",
    "                    all_metrics.append(metrics_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")\n",
    "\n",
    "            # Save once after collecting all building metrics\n",
    "            if all_metrics:\n",
    "                final_df = pd.concat(all_metrics, ignore_index=True)\n",
    "                output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "                final_df.to_csv(output_csv, index=False)  # âœ… Full overwrite\n",
    "                print(f\" Written to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Collecting metrics: gru | scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_scaffold: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 150.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Written to: metrics1411_grouped/gru_scaffold_metrics.csv\n",
      "\n",
      "ðŸ“Š Collecting metrics: gru | diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_diff: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 163.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Written to: metrics1411_grouped/gru_diff_metrics.csv\n",
      "\n",
      "ðŸ“Š Collecting metrics: lstm | scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lstm_scaffold: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 163.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Written to: metrics1411_grouped/lstm_scaffold_metrics.csv\n",
      "\n",
      "ðŸ“Š Collecting metrics: lstm | diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lstm_diff: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 168.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Written to: metrics1411_grouped/lstm_diff_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [\"scaffold\", \"diff\"]\n",
    "MODELS = [\"gru\", \"lstm\"]\n",
    "# CID = 45\n",
    "ROUNDS = list(range(9, 11))\n",
    "BASE_DIR = \"predictions1411\"\n",
    "BASE_OUTPUT_DIR = \"predictions1411\"\n",
    "METRICS_DIR = \"metrics1411_grouped\"\n",
    "# using evaluate_forecast_metrics_per_round\n",
    "\n",
    "get_model_metric_grouped_by_model_strategy(MODELS, \n",
    "                                           STRATEGIES, \n",
    "                                           ROUNDS, \n",
    "                                           BASE_PREDICTIONS_DIR=BASE_OUTPUT_DIR, \n",
    "                                           BASE_METRICS_DIR=METRICS_DIR,\n",
    "                                           METRIC=\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243aded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea6977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9854ebc7",
   "metadata": {},
   "source": [
    "# Now compute tabular statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ada2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_strategy_csv(Base_dir, Target_dir, round_num, METRIC, sortBy=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Computes boxplot statistics for each model_strategy CSV\n",
    "    and saves the pivot table in the target directory.\n",
    "\n",
    "    The metric column is dynamically named with METRIC.\n",
    "    \"\"\"\n",
    "    os.makedirs(Target_dir, exist_ok=True)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for csv_file in os.listdir(Base_dir):\n",
    "        if not csv_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(Base_dir, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the specified round\n",
    "        df_round = df[df[\"round\"] == round_num]\n",
    "\n",
    "        if df_round.empty:\n",
    "            print(f\"[SKIP] No round {round_num} in: {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        metric_values = df_round[METRIC].dropna()\n",
    "\n",
    "        # Compute stats\n",
    "        count = metric_values.count()\n",
    "        min_val = metric_values.min()\n",
    "        q1 = metric_values.quantile(0.25)\n",
    "        median = metric_values.median()\n",
    "        q3 = metric_values.quantile(0.75)\n",
    "        max_val = metric_values.max()\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Whiskers\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "\n",
    "        # Non-outlier min/max\n",
    "        non_outliers = metric_values[(metric_values >= lower_whisker) & (metric_values <= upper_whisker)]\n",
    "        min_non_outlier = non_outliers.min()\n",
    "        max_non_outlier = non_outliers.max()\n",
    "\n",
    "        # Extract model_strategy and strategy\n",
    "        model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "        try:\n",
    "            model, strategy = model_strategy.split(\"_\", 1)\n",
    "        except ValueError:\n",
    "            strategy = \"unknown\"\n",
    "\n",
    "        # âœ… The metric name is now a column with the median value.\n",
    "        row = {\n",
    "            \"Model_Strategy\": model_strategy,\n",
    "            # \"Strategy\": strategy,\n",
    "            \"Round\": round_num,\n",
    "            \"METRIC\": METRIC,  # dynamic metric column with value\n",
    "            \"Count\": count,\n",
    "            \"Min\": min_val,\n",
    "            \"Q1\": q1,\n",
    "            \"Median\": median,\n",
    "            \"Q3\": q3,\n",
    "            \"Max\": max_val,\n",
    "            \"IQR\": iqr,\n",
    "            # \"Lower Whisker\": lower_whisker,\n",
    "            # \"Upper Whisker\": upper_whisker,\n",
    "            \"True Min (Non-outlier)\": min_non_outlier,\n",
    "            \"True Max (Non-outlier)\": max_non_outlier\n",
    "        }\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    # Combine to DataFrame\n",
    "    pivot_df = pd.DataFrame(all_rows)\n",
    "    pivot_df.sort_values(by=sortBy, inplace=True)\n",
    "\n",
    "    # Clean output name\n",
    "    safe_metric = METRIC.replace(\" \", \"_\").replace(\"%\", \"percent\")\n",
    "    pivot_output = os.path.join(\n",
    "        Target_dir,\n",
    "        f\"all_stats_round{round_num}_metric_{safe_metric}_sort_by_{sortBy}.csv\"\n",
    "    )\n",
    "\n",
    "    pivot_df.to_csv(pivot_output, index=False)\n",
    "\n",
    "    print(f\"[OK] One-row-per-model_strategy pivot saved: {pivot_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0411dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all metrics CSVs into a single file that contains statistics for each model and strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfacab",
   "metadata": {},
   "source": [
    "for box plot combine all model stratetgy csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine data \n",
    "# import os\n",
    "\n",
    "# # Folder\n",
    "# BASE_METRICS_DIR = \"forecast_metrics_new_1411\"\n",
    "# combined = []\n",
    "\n",
    "# for csv_file in os.listdir(BASE_METRICS_DIR):\n",
    "#     if not csv_file.endswith(\".csv\"):\n",
    "#         continue\n",
    "\n",
    "#     csv_path = os.path.join(BASE_METRICS_DIR, csv_file)\n",
    "#     df = pd.read_csv(csv_path)\n",
    "\n",
    "#     # Make Model_Strategy for each row\n",
    "#     model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "#     df[\"Model_Strategy\"] = model_strategy\n",
    "\n",
    "#     combined.append(df)\n",
    "\n",
    "# # Combine all\n",
    "# big_df = pd.concat(combined, ignore_index=True)\n",
    "\n",
    "# # Correct path\n",
    "# output_csv = os.path.join(BASE_METRICS_DIR, \"saved_combined_data_round9_round10_1411.csv\")\n",
    "\n",
    "# # Save\n",
    "# big_df.to_csv(output_csv, index=False)\n",
    "# print(f\"[OK] Combined raw file saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de336733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def combine_metrics_csvs(\n",
    "    BASE_METRICS_DIR: str,\n",
    "    ROUNDS: List[int],\n",
    "    OUTPUT_FILENAME: str = \"saved_combined_metrics.csv\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Combines all *_metrics.csv files in the folder, filters by round,\n",
    "    and saves one combined CSV with Model_Strategy column.\n",
    "\n",
    "    Args:\n",
    "        BASE_METRICS_DIR (str): Folder containing metric CSV files.\n",
    "        ROUNDS (List[int]): List of rounds to include.\n",
    "        OUTPUT_FILENAME (str): Name of output combined CSV file.\n",
    "    \"\"\"\n",
    "    combined = []\n",
    "\n",
    "    for csv_file in os.listdir(BASE_METRICS_DIR):\n",
    "        if not csv_file.endswith(\"_metrics.csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(BASE_METRICS_DIR, csv_file)\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df = df[df[\"round\"].isin(ROUNDS)]  # Filter by rounds\n",
    "            df[\"Model_Strategy\"] = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "            combined.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not read {csv_file}: {e}\")\n",
    "\n",
    "    if combined:\n",
    "        final_df = pd.concat(combined, ignore_index=True)\n",
    "        output_csv = os.path.join(BASE_METRICS_DIR, OUTPUT_FILENAME)\n",
    "        final_df.to_csv(output_csv, index=False)\n",
    "        print(f\"[âœ”] Combined file saved: {output_csv}\")\n",
    "    else:\n",
    "        print(\"[âš ] No metrics files matched or found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# input_csv willl refer to the combined metrics CSV\n",
    "def plot_boxplot(input_csv, output_dir, metric_name, round_num, sortby=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Creates a boxplot for the given metric from the pivot CSV.\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Path to pivot CSV file.\n",
    "        output_dir (str): Directory to save the plot.\n",
    "        metric_name (str): Column name to plot on Y-axis.\n",
    "        round_num (int): Round number for file naming.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the pivot CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    if metric_name not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric_name}' not found in the CSV columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Sort X-axis by Model_Strategy for clean look\n",
    "    df = df.sort_values(by=sortby)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.boxplot(df[metric_name], vert=True)\n",
    "    plt.xticks([1], [metric_name])\n",
    "    plt.title(f\"{metric_name} Boxplot for Round {round_num}\")\n",
    "    plt.ylabel(metric_name)\n",
    "    \n",
    "    # Save plot\n",
    "    plot_name = f\"{metric_name}_round{round_num}_sorting_strategy{sortby}_pivot_boxplot.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_name)\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[OK] Boxplot saved: {plot_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
