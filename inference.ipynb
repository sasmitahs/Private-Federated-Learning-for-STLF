{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1518ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from Models import MoELSTM\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import random\n",
    "from Models import MoELSTM, LSTMModel, train_model\n",
    "from Preprocess import (\n",
    "    compute_metrics,\n",
    "    convert_timeseries_to_numpy,\n",
    "    create_dataloader,\n",
    "    load_building_series,\n",
    "    split_series_list,\n",
    ")\n",
    "from Models import model_fn\n",
    "from tqdm import tqdm\n",
    "from my_utils import train_model, load_energy_data_feather, get_weights, set_weights\n",
    "from energy_ts_diffusion.task import convert_timeseries_to_numpy  # adjust as per your project\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06b21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def rolling_forecast_on_test(cid, model, filepath=\"train_final.feather\", input_len=24, output_len=8):\n",
    "    \"\"\"\n",
    "    Perform rolling window forecast on the test data using a trained model and return\n",
    "    unscaled predictions and ground truths with actual timestamps.\n",
    "\n",
    "    Args:\n",
    "        cid (int): Client/building ID.\n",
    "        model (nn.Module): Trained PyTorch model.\n",
    "        filepath (str): Path to the Feather file.\n",
    "        input_len (int): Input sequence length.\n",
    "        output_len (int): Prediction horizon.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[TimeSeries], List[TimeSeries]]: (predictions_ts_list, ground_truth_ts_list)\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] rolling_forecast_on_test: CID={cid}\")\n",
    "\n",
    "    # Load and filter data\n",
    "    df = pd.read_feather(filepath)\n",
    "    df = df[df['building_id'] == cid]\n",
    "    df['meter_reading'] = df['meter_reading'].fillna(0)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found for building_id {cid}\")\n",
    "\n",
    "    # Create TimeSeries and scale\n",
    "    ts = TimeSeries.from_dataframe(\n",
    "        df,\n",
    "        time_col='timestamp',\n",
    "        value_cols='meter_reading',\n",
    "        fill_missing_dates=True,\n",
    "        freq='h'\n",
    "    )\n",
    "\n",
    "    _, test_series = ts.split_before(0.75)\n",
    "\n",
    "    # Scale\n",
    "    scaler = MinMaxScaler(feature_range=(0.1, 1))\n",
    "    transformer = Scaler(scaler)\n",
    "    test_series_scaled = transformer.fit_transform(test_series)\n",
    "\n",
    "    test_values_scaled = test_series_scaled.values().squeeze()\n",
    "    test_timestamps = test_series_scaled.time_index\n",
    "\n",
    "    predictions_ts_list = []\n",
    "    ground_truth_ts_list = []\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    device = 'cuda'\n",
    "    for i in range(0, len(test_values_scaled) - input_len - output_len + 1):\n",
    "        input_seq = test_values_scaled[i:i+input_len]\n",
    "        true_output = test_values_scaled[i+input_len:i+input_len+output_len]\n",
    "        true_time = test_timestamps[i+input_len:i+input_len+output_len]\n",
    "\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)  # [1, input_len, 1]\n",
    "\n",
    "        pred = model(input_tensor)\n",
    "        \n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.squeeze(0).squeeze(-1)\n",
    "        else:\n",
    "            pred = pred.squeeze(0)\n",
    "\n",
    "        # Convert prediction & ground truth to TimeSeries\n",
    "        pred_ts = TimeSeries.from_times_and_values(true_time, pred.cpu().numpy())\n",
    "        true_ts = TimeSeries.from_times_and_values(true_time, true_output)\n",
    "\n",
    "        # Inverse transform\n",
    "        pred_unscaled = transformer.inverse_transform(pred_ts)\n",
    "        true_unscaled = transformer.inverse_transform(true_ts)\n",
    "\n",
    "        predictions_ts_list.append(pred_unscaled)\n",
    "        ground_truth_ts_list.append(true_unscaled)\n",
    "\n",
    "    return predictions_ts_list, ground_truth_ts_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2ddc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions and save to CSV\n",
    "# This function will load the model for each round, perform predictions, and save results to a CSV file. - call rolling_forecast_on_test\n",
    "def get_model_predictions_csv(model_name: str, cid: int,aggr_strat: str ,rounds: list, model_dir: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    For each round, load the model, predict on test set for cid, and save all preds in a single CSV.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for rnd in tqdm(rounds):\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_round_{rnd}_{aggr_strat}.pt\")\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"[WARN] Model not found: {model_path}\")\n",
    "            continue\n",
    "\n",
    "        model = model_fn(model_name)\n",
    "        # model.load_state_dict(torch.load(model_path), weights_only=True)  # Ensure weights_only=True if using a custom model\n",
    "        state_dict = torch.load(model_path, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to('cuda')\n",
    "        model.eval()\n",
    "\n",
    "        pred_ts_list, gt_ts_list = rolling_forecast_on_test(cid=cid, model=model)\n",
    "\n",
    "        for pred_ts, true_ts in zip(pred_ts_list, gt_ts_list):\n",
    "            df_pred = pd.DataFrame({\"timestamp\": pred_ts.time_index, \"pred\": pred_ts.values().squeeze()})\n",
    "            df_true = pd.DataFrame({\"timestamp\": true_ts.time_index, \"true\": true_ts.values().squeeze()})\n",
    "\n",
    "            # df_merged = df_true.join(df_pred, how=\"inner\")\n",
    "            df_merged = pd.merge(df_true, df_pred, on=\"timestamp\", how=\"inner\")\n",
    "            df_merged[\"round\"] = rnd\n",
    "\n",
    "\n",
    "            rows.append(df_merged[[\"timestamp\", \"true\", \"pred\", \"round\"]])\n",
    "\n",
    "    # Combine all rows\n",
    "    final_df = pd.concat(rows, ignore_index=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"[INFO] Forecasts written to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fe58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_strategy_csv(Base_dir, Target_dir, round_num, METRIC, sortBy=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Computes boxplot statistics for each model_strategy CSV\n",
    "    and saves the pivot table in the target directory.\n",
    "\n",
    "    The metric column is dynamically named with METRIC.\n",
    "    \"\"\"\n",
    "    os.makedirs(Target_dir, exist_ok=True)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for csv_file in os.listdir(Base_dir):\n",
    "        if not csv_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(Base_dir, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the specified round\n",
    "        df_round = df[df[\"round\"] == round_num]\n",
    "\n",
    "        if df_round.empty:\n",
    "            print(f\"[SKIP] No round {round_num} in: {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        metric_values = df_round[METRIC].dropna()\n",
    "\n",
    "        # Compute stats\n",
    "        count = metric_values.count()\n",
    "        min_val = metric_values.min()\n",
    "        q1 = metric_values.quantile(0.25)\n",
    "        median = metric_values.median()\n",
    "        q3 = metric_values.quantile(0.75)\n",
    "        max_val = metric_values.max()\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Whiskers\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "\n",
    "        # Non-outlier min/max\n",
    "        non_outliers = metric_values[(metric_values >= lower_whisker) & (metric_values <= upper_whisker)]\n",
    "        min_non_outlier = non_outliers.min()\n",
    "        max_non_outlier = non_outliers.max()\n",
    "\n",
    "        # Extract model_strategy and strategy\n",
    "        model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "        try:\n",
    "            model, strategy = model_strategy.split(\"_\", 1)\n",
    "        except ValueError:\n",
    "            strategy = \"unknown\"\n",
    "\n",
    "        # ✅ The metric name is now a column with the median value.\n",
    "        row = {\n",
    "            \"Model_Strategy\": model_strategy,\n",
    "            # \"Strategy\": strategy,\n",
    "            \"Round\": round_num,\n",
    "            \"METRIC\": METRIC,  # dynamic metric column with value\n",
    "            \"Count\": count,\n",
    "            \"Min\": min_val,\n",
    "            \"Q1\": q1,\n",
    "            \"Median\": median,\n",
    "            \"Q3\": q3,\n",
    "            \"Max\": max_val,\n",
    "            \"IQR\": iqr,\n",
    "            # \"Lower Whisker\": lower_whisker,\n",
    "            # \"Upper Whisker\": upper_whisker,\n",
    "            \"True Min (Non-outlier)\": min_non_outlier,\n",
    "            \"True Max (Non-outlier)\": max_non_outlier\n",
    "        }\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    # Combine to DataFrame\n",
    "    pivot_df = pd.DataFrame(all_rows)\n",
    "    pivot_df.sort_values(by=sortBy, inplace=True)\n",
    "\n",
    "    # Clean output name\n",
    "    safe_metric = METRIC.replace(\" \", \"_\").replace(\"%\", \"percent\")\n",
    "    pivot_output = os.path.join(\n",
    "        Target_dir,\n",
    "        f\"all_stats_round{round_num}_metric_{safe_metric}_sort_by_{sortBy}.csv\"\n",
    "    )\n",
    "\n",
    "    pivot_df.to_csv(pivot_output, index=False)\n",
    "\n",
    "    print(f\"[OK] One-row-per-model_strategy pivot saved: {pivot_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e13744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate forecasts - working correctly 1411 buildings count \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    return np.mean(np.where(denominator == 0, 0, np.abs(y_true - y_pred) / denominator)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error.\"\"\"\n",
    "    y_true = np.where(y_true == 0, 1e-8, y_true)  # avoid division by zero\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def evaluate_forecast_metrics_per_round(csv_path):\n",
    "    \"\"\"\n",
    "    Reads forecast CSV and computes MAPE, MAE, SMAPE, RMSE, and MSE per round.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV with columns: timestamp, true, pred, round\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Metrics summary per round\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"CSV is empty or invalid\")\n",
    "\n",
    "    metrics_list = []\n",
    "\n",
    "    for rnd in sorted(df['round'].unique()):\n",
    "\n",
    "        df_rnd = df[df['round'] == rnd]\n",
    "        df_rnd = df_rnd.fillna(0.005)\n",
    "        y_true = df_rnd[\"true\"].values\n",
    "        y_pred = df_rnd[\"pred\"].values\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape_val = mape(y_true, y_pred)\n",
    "        smape_val = smape(y_true, y_pred)\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"round\": rnd,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE (%)\": mape_val,\n",
    "            \"SMAPE (%)\": smape_val\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72361cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the model_strategy_csv of round 10 ,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d144020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try in function\n",
    "def get_model_metric_grouped_by_model_strategy(\n",
    "    MODELS: List[str],\n",
    "    STRATEGIES: List[str],\n",
    "    ROUNDS: List[int],\n",
    "    BASE_PREDICTIONS_DIR: str,\n",
    "    BASE_METRICS_DIR: str,\n",
    "    METRIC: str = \"MAE\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    \n",
    "    Args:\n",
    "        MODELS (List[str]): List of model names.\n",
    "        STRATEGIES (List[str]): List of strategy names.\n",
    "        ROUNDS (List[int]): List of round numbers.\n",
    "        BASE_PREDICTIONS_DIR (str): Directory containing prediction CSVs.\n",
    "        BASE_METRICS_DIR (str): Directory to save metrics CSVs.\n",
    "        METRIC (str): The metric to compute, e.g., \"MAE\", \"MSE\", etc.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for CID in tqdm(range(1411), desc=\"Processing Client IDs\"):\n",
    "        for model_name in MODELS:\n",
    "            for strategy in STRATEGIES:\n",
    "                input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "                output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "                if not os.path.isfile(input_csv):\n",
    "                    print(f\"[SKIP] Missing: {input_csv}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Compute metrics for the given CSV\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "                    metrics_df.insert(0, \"building_id\", CID)  # add client ID\n",
    "                    metrics_df.insert(1, \"model\", model_name)\n",
    "                    metrics_df.insert(2, \"strategy\", strategy)\n",
    "\n",
    "                    if os.path.isfile(output_csv):\n",
    "                        metrics_df.to_csv(output_csv, index=False)\n",
    "                    else:\n",
    "                        metrics_df.to_csv(output_csv, index=False)\n",
    "\n",
    "                    print(f\"[OK] {output_csv} <- CID {CID}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c422bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b12a20e2",
   "metadata": {},
   "source": [
    "## Predicitons metric both (above code in function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c4b94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model List , strategy List, round List, base_results_dir, base_output_dir, metrics_dir,cid range\n",
    "\n",
    "# # Model List , strategy List, round List, base_results_dir, base_output_dir, metrics_dir,cid range\n",
    "\n",
    "import os\n",
    "\n",
    "def get_model_predictions_metric(\n",
    "    MODELS,\n",
    "    STRATEGIES,\n",
    "    ROUNDS,\n",
    "    BASE_RESULTS_DIR: str,\n",
    "    BASE_OUTPUT_DIR: str,\n",
    "    METRICS_DIR: str,\n",
    "    CID: range\n",
    "):\n",
    "    \"\"\"\n",
    "    For each client in CID, model in MODELS, and strategy in STRATEGIES,\n",
    "    generates forecast predictions and computes metrics.\n",
    "\n",
    "    Args:\n",
    "        MODELS (List[str]): List of model names (e.g., [\"gru\", \"lstm\"])\n",
    "        STRATEGIES (List[str]): List of aggregation strategies (e.g., [\"_scaffold\", \"_diff\"])\n",
    "        ROUNDS (List[int]): Rounds to evaluate (e.g., list(range(9, 11)))\n",
    "        BASE_RESULTS_DIR (str): Directory containing saved model weights.\n",
    "        BASE_OUTPUT_DIR (str): Directory to save prediction CSVs.\n",
    "        METRICS_DIR (str): Directory to save metric CSVs.\n",
    "        CID (range): Range of client IDs (e.g., range(1411))\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for cid in CID:\n",
    "        print(f\"\\nProcessing Client ID: {cid}\")\n",
    "\n",
    "        for model_name in MODELS:\n",
    "            for strategy in STRATEGIES:\n",
    "                model_dir = os.path.join(BASE_RESULTS_DIR, model_name)\n",
    "                output_csv = os.path.join(BASE_OUTPUT_DIR, f\"{cid}_{model_name}_{strategy}.csv\")\n",
    "                metrics_csv = os.path.join(METRICS_DIR, f\"cid{cid}_{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "                print(f\"\\n Model: {model_name}, Strategy: {strategy}\")\n",
    "\n",
    "                try:\n",
    "                    # Generate predictions and save to CSV\n",
    "                    get_model_predictions_csv(\n",
    "                        model_name=model_name,\n",
    "                        cid=cid,\n",
    "                        rounds=ROUNDS,\n",
    "                        model_dir=model_dir,\n",
    "                        output_csv=output_csv,\n",
    "                        aggr_strat=strategy\n",
    "                    )\n",
    "\n",
    "                    # Evaluate metrics and save to CSV\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(output_csv)\n",
    "                    metrics_df.to_csv(metrics_csv, index=False)\n",
    "                    print(f\"Metrics saved to {metrics_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] model={model_name}, strategy={strategy}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e20acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Client ID: 0\n",
      "\n",
      " Model: lstm, Strategy: fedAvg_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:19,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:08,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_lstm_fedAvg_lr.csv\n",
      "Metrics saved to metrics1411/cid0_lstm_fedAvg_lr_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: das\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:13,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_lstm_das.csv\n",
      "Metrics saved to metrics1411/cid0_lstm_das_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: diff_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:22,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:13,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:10,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:08,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_lstm_diff_lr.csv\n",
      "Metrics saved to metrics1411/cid0_lstm_diff_lr_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: scaffold_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:20,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:11,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:08,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_lstm_scaffold_diff.csv\n",
      "Metrics saved to metrics1411/cid0_lstm_scaffold_diff_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: scaffold_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_lstm_scaffold_lr.csv\n",
      "Metrics saved to metrics1411/cid0_lstm_scaffold_lr_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: fedAvg_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:11,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_gru_fedAvg_lr.csv\n",
      "Metrics saved to metrics1411/cid0_gru_fedAvg_lr_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: das\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_gru_das.csv\n",
      "Metrics saved to metrics1411/cid0_gru_das_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: diff_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_gru_diff_lr.csv\n",
      "Metrics saved to metrics1411/cid0_gru_diff_lr_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: scaffold_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:15,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:13,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:07<00:11,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:09<00:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:17<00:01,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_gru_scaffold_diff.csv\n",
      "Metrics saved to metrics1411/cid0_gru_scaffold_diff_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: scaffold_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:16,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:14,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:07<00:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:09<00:09,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:11<00:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:13<00:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:15<00:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:17<00:01,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/0_gru_scaffold_lr.csv\n",
      "Metrics saved to metrics1411/cid0_gru_scaffold_lr_metrics.csv\n",
      "\n",
      "Processing Client ID: 1\n",
      "\n",
      " Model: lstm, Strategy: fedAvg_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:20,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:13,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:05,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/1_lstm_fedAvg_lr.csv\n",
      "Metrics saved to metrics1411/cid1_lstm_fedAvg_lr_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: das\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:20,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/1_lstm_das.csv\n",
      "Metrics saved to metrics1411/cid1_lstm_das_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: diff_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/1_lstm_diff_lr.csv\n",
      "Metrics saved to metrics1411/cid1_lstm_diff_lr_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: scaffold_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:19,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:13,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:11,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/1_lstm_scaffold_diff.csv\n",
      "Metrics saved to metrics1411/cid1_lstm_scaffold_diff_metrics.csv\n",
      "\n",
      " Model: lstm, Strategy: scaffold_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:23,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:14,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:09,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:16<00:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:18<00:04,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Forecasts written to predictions1411/1_lstm_scaffold_lr.csv\n",
      "Metrics saved to metrics1411/cid1_lstm_scaffold_lr_metrics.csv\n",
      "\n",
      " Model: gru, Strategy: fedAvg_lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:21,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:16,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] rolling_forecast_on_test: CID=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:07<00:17,  2.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m METRICS_DIR = \u001b[33m\"\u001b[39m\u001b[33mmetrics1411\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m CID = \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,\u001b[32m500\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mget_model_predictions_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSTRATEGIES\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTRATEGIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mROUNDS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROUNDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBASE_RESULTS_DIR\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_RESULTS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBASE_OUTPUT_DIR\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_OUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMETRICS_DIR\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMETRICS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCID\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCID\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mget_model_predictions_metric\u001b[39m\u001b[34m(MODELS, STRATEGIES, ROUNDS, BASE_RESULTS_DIR, BASE_OUTPUT_DIR, METRICS_DIR, CID)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Generate predictions and save to CSV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mget_model_predictions_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROUNDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggr_strat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Evaluate metrics and save to CSV\u001b[39;00m\n\u001b[32m     55\u001b[39m     metrics_df = evaluate_forecast_metrics_per_round(output_csv)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_model_predictions_csv\u001b[39m\u001b[34m(model_name, cid, aggr_strat, rounds, model_dir, output_csv)\u001b[39m\n\u001b[32m     20\u001b[39m model = model.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m pred_ts_list, gt_ts_list = \u001b[43mrolling_forecast_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred_ts, true_ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pred_ts_list, gt_ts_list):\n\u001b[32m     26\u001b[39m     df_pred = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.time_index, \u001b[33m\"\u001b[39m\u001b[33mpred\u001b[39m\u001b[33m\"\u001b[39m: pred_ts.values().squeeze()})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mrolling_forecast_on_test\u001b[39m\u001b[34m(cid, model, filepath, input_len, output_len)\u001b[39m\n\u001b[32m     55\u001b[39m true_time = test_timestamps[i+input_len:i+input_len+output_len]\n\u001b[32m     57\u001b[39m input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(\u001b[32m0\u001b[39m).unsqueeze(-\u001b[32m1\u001b[39m).to(device)  \u001b[38;5;66;03m# [1, input_len, 1]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred.dim() == \u001b[32m3\u001b[39m:\n\u001b[32m     62\u001b[39m     pred = pred.squeeze(\u001b[32m0\u001b[39m).squeeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Priyankan/Diffusion_FL/energy-ts-diffusion/Models.py:189\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/flower/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1372\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hx.dim() != \u001b[32m3\u001b[39m:\n\u001b[32m   1369\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1370\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFor batched 3-D input, hx should also be 3-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-D tensor\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m max_batch_size = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m.size(\u001b[32m1\u001b[39m)\n\u001b[32m   1373\u001b[39m sorted_indices = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1374\u001b[39m unsorted_indices = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "STRATEGIES = [\"fedAvg_lr\",\"das\",\"diff_lr\",\"scaffold_diff\",\"scaffold_lr\" ] # scaffold_diff, \"diff_lr2\",\"das11\",\"das2\", \"fedAvg_lr\",\"fedAvg_diffsample_dhc\"\n",
    "MODELS = [ \"lstm\",\"gru\"] #,\"gru\"\n",
    "# CID = 45\n",
    "ROUNDS = list(range(40, 50))\n",
    "BASE_RESULTS_DIR = \"results\"\n",
    "BASE_OUTPUT_DIR = \"predictions1411\"\n",
    "METRICS_DIR = \"metrics1411\"\n",
    "CID = range(0,500) \n",
    "\n",
    "get_model_predictions_metric(\n",
    "    MODELS=MODELS,\n",
    "    STRATEGIES=STRATEGIES,\n",
    "    ROUNDS=ROUNDS,\n",
    "    BASE_RESULTS_DIR=BASE_RESULTS_DIR,\n",
    "    BASE_OUTPUT_DIR=BASE_OUTPUT_DIR,\n",
    "    METRICS_DIR=METRICS_DIR,\n",
    "    CID=CID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809a1ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Client ID: 70\n",
      "\n",
      " Model: lstm, Strategy: fedProx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 112552.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Model not found: results/lstm/lstm_round_1_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_2_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_3_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_4_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_5_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_6_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_7_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_8_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_9_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_10_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_11_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_12_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_13_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_14_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_15_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_16_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_17_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_18_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_19_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_20_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_21_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_22_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_23_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_24_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_25_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_26_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_27_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_28_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_29_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_30_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_31_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_32_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_33_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_34_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_35_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_36_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_37_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_38_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_39_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_40_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_41_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_42_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_43_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_44_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_45_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_46_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_47_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_48_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_49_fedProx.pt\n",
      "[ERROR] model=lstm, strategy=fedProx: No objects to concatenate\n",
      "\n",
      " Model: gru, Strategy: fedProx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 45813.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Model not found: results/gru/gru_round_1_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_2_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_3_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_4_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_5_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_6_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_7_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_8_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_9_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_10_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_11_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_12_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_13_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_14_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_15_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_16_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_17_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_18_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_19_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_20_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_21_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_22_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_23_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_24_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_25_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_26_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_27_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_28_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_29_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_30_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_31_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_32_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_33_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_34_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_35_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_36_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_37_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_38_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_39_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_40_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_41_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_42_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_43_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_44_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_45_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_46_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_47_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_48_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_49_fedProx.pt\n",
      "[ERROR] model=gru, strategy=fedProx: No objects to concatenate\n",
      "\n",
      "Processing Client ID: 71\n",
      "\n",
      " Model: lstm, Strategy: fedProx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 160437.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Model not found: results/lstm/lstm_round_1_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_2_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_3_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_4_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_5_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_6_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_7_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_8_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_9_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_10_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_11_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_12_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_13_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_14_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_15_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_16_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_17_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_18_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_19_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_20_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_21_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_22_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_23_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_24_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_25_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_26_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_27_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_28_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_29_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_30_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_31_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_32_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_33_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_34_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_35_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_36_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_37_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_38_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_39_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_40_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_41_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_42_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_43_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_44_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_45_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_46_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_47_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_48_fedProx.pt\n",
      "[WARN] Model not found: results/lstm/lstm_round_49_fedProx.pt\n",
      "[ERROR] model=lstm, strategy=fedProx: No objects to concatenate\n",
      "\n",
      " Model: gru, Strategy: fedProx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 204092.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Model not found: results/gru/gru_round_1_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_2_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_3_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_4_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_5_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_6_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_7_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_8_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_9_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_10_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_11_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_12_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_13_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_14_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_15_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_16_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_17_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_18_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_19_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_20_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_21_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_22_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_23_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_24_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_25_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_26_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_27_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_28_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_29_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_30_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_31_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_32_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_33_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_34_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_35_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_36_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_37_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_38_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_39_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_40_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_41_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_42_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_43_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_44_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_45_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_46_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_47_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_48_fedProx.pt\n",
      "[WARN] Model not found: results/gru/gru_round_49_fedProx.pt\n",
      "[ERROR] model=gru, strategy=fedProx: No objects to concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [\"fedProx\" ] # scaffold_diff\"scaffold_lr\", \"diff_lr2\",\"das11\",\"das2\", \"fedAvg_lr\",\"fedAvg_diffsample_dhc\"\n",
    "MODELS = [ \"lstm\",\"gru\"] #,\"gru\"\n",
    "# CID = 45\n",
    "ROUNDS = list(range(1, 50))\n",
    "BASE_RESULTS_DIR = \"results\"\n",
    "BASE_OUTPUT_DIR = \"predictions1411\"\n",
    "METRICS_DIR = \"metrics1411\"\n",
    "CID = range(70,72) \n",
    "\n",
    "get_model_predictions_metric(\n",
    "    MODELS=MODELS,\n",
    "    STRATEGIES=STRATEGIES,\n",
    "    ROUNDS=ROUNDS,\n",
    "    BASE_RESULTS_DIR=BASE_RESULTS_DIR,\n",
    "    BASE_OUTPUT_DIR=BASE_OUTPUT_DIR,\n",
    "    METRICS_DIR=METRICS_DIR,\n",
    "    CID=CID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9daf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace84dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try in function\n",
    "# def get_model_metric_grouped_by_model_strategy(\n",
    "#     MODELS: List[str],\n",
    "#     STRATEGIES: List[str],\n",
    "#     ROUNDS: List[int],\n",
    "#     BASE_PREDICTIONS_DIR: str,\n",
    "#     BASE_METRICS_DIR: str,\n",
    "#     METRIC: str = \"MAE\"\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    \n",
    "#     Args:\n",
    "#         MODELS (List[str]): List of model names.\n",
    "#         STRATEGIES (List[str]): List of strategy names.\n",
    "#         ROUNDS (List[int]): List of round numbers.\n",
    "#         BASE_PREDICTIONS_DIR (str): Directory containing prediction CSVs.\n",
    "#         BASE_METRICS_DIR (str): Directory to save metrics CSVs.\n",
    "#         METRIC (str): The metric to compute, e.g., \"MAE\", \"MSE\", etc.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "#     for CID in tqdm(range(1411), desc=\"Processing Client IDs\"):\n",
    "#         for model_name in MODELS:\n",
    "#             for strategy in STRATEGIES:\n",
    "#                 input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "#                 output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "\n",
    "#                 if not os.path.isfile(input_csv):\n",
    "#                     print(f\"[SKIP] Missing: {input_csv}\")\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     # Compute metrics for the given CSV\n",
    "#                     metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "#                     metrics_df.insert(0, \"building_id\", CID)  # add client ID\n",
    "#                     metrics_df.insert(1, \"model\", model_name)\n",
    "#                     metrics_df.insert(2, \"strategy\", strategy)\n",
    "\n",
    "#                     if os.path.isfile(output_csv):\n",
    "#                         metrics_df.to_csv(output_csv, index=False)\n",
    "#                     else:\n",
    "#                         metrics_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"[OK] {output_csv} <- CID {CID}\")\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_model_metric_grouped_by_model_strategy(\n",
    "    MODELS: List[str],\n",
    "    STRATEGIES: List[str],\n",
    "    ROUNDS: List[int],\n",
    "    BASE_PREDICTIONS_DIR: str,\n",
    "    BASE_METRICS_DIR: str,\n",
    "    METRIC: str = \"MAE\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Computes metrics for each model and strategy, grouped by client ID and round.\n",
    "    Overwrites existing CSVs with combined results for all building IDs.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    for model_name in MODELS:\n",
    "        for strategy in STRATEGIES:\n",
    "            all_metrics = []  # Accumulate metrics per model-strategy\n",
    "            print(f\"\\n📊 Collecting metrics: {model_name} | {strategy}\")\n",
    "\n",
    "            for CID in tqdm(range(1411), desc=f\"{model_name}_{strategy}\"):\n",
    "                input_csv = os.path.join(BASE_PREDICTIONS_DIR, f\"{CID}_{model_name}_{strategy}.csv\")\n",
    "\n",
    "                if not os.path.isfile(input_csv):\n",
    "                    print(f\"[SKIP] Missing: {input_csv}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    metrics_df = evaluate_forecast_metrics_per_round(input_csv)\n",
    "                    metrics_df.insert(0, \"building_id\", CID)\n",
    "                    metrics_df.insert(1, \"model\", model_name)\n",
    "                    metrics_df.insert(2, \"strategy\", strategy)\n",
    "                    all_metrics.append(metrics_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] CID={CID} | {model_name}{strategy} | {e}\")\n",
    "\n",
    "            # Save once after collecting all building metrics\n",
    "            if all_metrics:\n",
    "                final_df = pd.concat(all_metrics, ignore_index=True)\n",
    "                output_csv = os.path.join(BASE_METRICS_DIR, f\"{model_name}_{strategy}_metrics.csv\")\n",
    "                final_df.to_csv(output_csv, index=False)  # ✅ Full overwrite\n",
    "                print(f\" Written to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Collecting metrics: gru | scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_scaffold: 100%|██████████| 5/5 [00:00<00:00, 150.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Written to: metrics1411_grouped/gru_scaffold_metrics.csv\n",
      "\n",
      "📊 Collecting metrics: gru | diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_diff: 100%|██████████| 5/5 [00:00<00:00, 163.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Written to: metrics1411_grouped/gru_diff_metrics.csv\n",
      "\n",
      "📊 Collecting metrics: lstm | scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lstm_scaffold: 100%|██████████| 5/5 [00:00<00:00, 163.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Written to: metrics1411_grouped/lstm_scaffold_metrics.csv\n",
      "\n",
      "📊 Collecting metrics: lstm | diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lstm_diff: 100%|██████████| 5/5 [00:00<00:00, 168.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Written to: metrics1411_grouped/lstm_diff_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [\"scaffold\", \"diff\"]\n",
    "MODELS = [\"gru\", \"lstm\"]\n",
    "# CID = 45\n",
    "ROUNDS = list(range(9, 11))\n",
    "BASE_DIR = \"predictions1411\"\n",
    "BASE_OUTPUT_DIR = \"predictions1411\"\n",
    "METRICS_DIR = \"metrics1411_grouped\"\n",
    "# using evaluate_forecast_metrics_per_round\n",
    "\n",
    "get_model_metric_grouped_by_model_strategy(MODELS, \n",
    "                                           STRATEGIES, \n",
    "                                           ROUNDS, \n",
    "                                           BASE_PREDICTIONS_DIR=BASE_OUTPUT_DIR, \n",
    "                                           BASE_METRICS_DIR=METRICS_DIR,\n",
    "                                           METRIC=\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243aded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea6977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9854ebc7",
   "metadata": {},
   "source": [
    "# Now compute tabular statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ada2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_strategy_csv(Base_dir, Target_dir, round_num, METRIC, sortBy=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Computes boxplot statistics for each model_strategy CSV\n",
    "    and saves the pivot table in the target directory.\n",
    "\n",
    "    The metric column is dynamically named with METRIC.\n",
    "    \"\"\"\n",
    "    os.makedirs(Target_dir, exist_ok=True)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for csv_file in os.listdir(Base_dir):\n",
    "        if not csv_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(Base_dir, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the specified round\n",
    "        df_round = df[df[\"round\"] == round_num]\n",
    "\n",
    "        if df_round.empty:\n",
    "            print(f\"[SKIP] No round {round_num} in: {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        metric_values = df_round[METRIC].dropna()\n",
    "\n",
    "        # Compute stats\n",
    "        count = metric_values.count()\n",
    "        min_val = metric_values.min()\n",
    "        q1 = metric_values.quantile(0.25)\n",
    "        median = metric_values.median()\n",
    "        q3 = metric_values.quantile(0.75)\n",
    "        max_val = metric_values.max()\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Whiskers\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "\n",
    "        # Non-outlier min/max\n",
    "        non_outliers = metric_values[(metric_values >= lower_whisker) & (metric_values <= upper_whisker)]\n",
    "        min_non_outlier = non_outliers.min()\n",
    "        max_non_outlier = non_outliers.max()\n",
    "\n",
    "        # Extract model_strategy and strategy\n",
    "        model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "        try:\n",
    "            model, strategy = model_strategy.split(\"_\", 1)\n",
    "        except ValueError:\n",
    "            strategy = \"unknown\"\n",
    "\n",
    "        # ✅ The metric name is now a column with the median value.\n",
    "        row = {\n",
    "            \"Model_Strategy\": model_strategy,\n",
    "            # \"Strategy\": strategy,\n",
    "            \"Round\": round_num,\n",
    "            \"METRIC\": METRIC,  # dynamic metric column with value\n",
    "            \"Count\": count,\n",
    "            \"Min\": min_val,\n",
    "            \"Q1\": q1,\n",
    "            \"Median\": median,\n",
    "            \"Q3\": q3,\n",
    "            \"Max\": max_val,\n",
    "            \"IQR\": iqr,\n",
    "            # \"Lower Whisker\": lower_whisker,\n",
    "            # \"Upper Whisker\": upper_whisker,\n",
    "            \"True Min (Non-outlier)\": min_non_outlier,\n",
    "            \"True Max (Non-outlier)\": max_non_outlier\n",
    "        }\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    # Combine to DataFrame\n",
    "    pivot_df = pd.DataFrame(all_rows)\n",
    "    pivot_df.sort_values(by=sortBy, inplace=True)\n",
    "\n",
    "    # Clean output name\n",
    "    safe_metric = METRIC.replace(\" \", \"_\").replace(\"%\", \"percent\")\n",
    "    pivot_output = os.path.join(\n",
    "        Target_dir,\n",
    "        f\"all_stats_round{round_num}_metric_{safe_metric}_sort_by_{sortBy}.csv\"\n",
    "    )\n",
    "\n",
    "    pivot_df.to_csv(pivot_output, index=False)\n",
    "\n",
    "    print(f\"[OK] One-row-per-model_strategy pivot saved: {pivot_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0411dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all metrics CSVs into a single file that contains statistics for each model and strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfacab",
   "metadata": {},
   "source": [
    "for box plot combine all model stratetgy csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine data \n",
    "# import os\n",
    "\n",
    "# # Folder\n",
    "# BASE_METRICS_DIR = \"forecast_metrics_new_1411\"\n",
    "# combined = []\n",
    "\n",
    "# for csv_file in os.listdir(BASE_METRICS_DIR):\n",
    "#     if not csv_file.endswith(\".csv\"):\n",
    "#         continue\n",
    "\n",
    "#     csv_path = os.path.join(BASE_METRICS_DIR, csv_file)\n",
    "#     df = pd.read_csv(csv_path)\n",
    "\n",
    "#     # Make Model_Strategy for each row\n",
    "#     model_strategy = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "#     df[\"Model_Strategy\"] = model_strategy\n",
    "\n",
    "#     combined.append(df)\n",
    "\n",
    "# # Combine all\n",
    "# big_df = pd.concat(combined, ignore_index=True)\n",
    "\n",
    "# # Correct path\n",
    "# output_csv = os.path.join(BASE_METRICS_DIR, \"saved_combined_data_round9_round10_1411.csv\")\n",
    "\n",
    "# # Save\n",
    "# big_df.to_csv(output_csv, index=False)\n",
    "# print(f\"[OK] Combined raw file saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de336733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def combine_metrics_csvs(\n",
    "    BASE_METRICS_DIR: str,\n",
    "    ROUNDS: List[int],\n",
    "    OUTPUT_FILENAME: str = \"saved_combined_metrics.csv\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Combines all *_metrics.csv files in the folder, filters by round,\n",
    "    and saves one combined CSV with Model_Strategy column.\n",
    "\n",
    "    Args:\n",
    "        BASE_METRICS_DIR (str): Folder containing metric CSV files.\n",
    "        ROUNDS (List[int]): List of rounds to include.\n",
    "        OUTPUT_FILENAME (str): Name of output combined CSV file.\n",
    "    \"\"\"\n",
    "    combined = []\n",
    "\n",
    "    for csv_file in os.listdir(BASE_METRICS_DIR):\n",
    "        if not csv_file.endswith(\"_metrics.csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(BASE_METRICS_DIR, csv_file)\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df = df[df[\"round\"].isin(ROUNDS)]  # Filter by rounds\n",
    "            df[\"Model_Strategy\"] = csv_file.replace(\"_metrics.csv\", \"\")\n",
    "            combined.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not read {csv_file}: {e}\")\n",
    "\n",
    "    if combined:\n",
    "        final_df = pd.concat(combined, ignore_index=True)\n",
    "        output_csv = os.path.join(BASE_METRICS_DIR, OUTPUT_FILENAME)\n",
    "        final_df.to_csv(output_csv, index=False)\n",
    "        print(f\"[✔] Combined file saved: {output_csv}\")\n",
    "    else:\n",
    "        print(\"[⚠] No metrics files matched or found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# input_csv willl refer to the combined metrics CSV\n",
    "def plot_boxplot(input_csv, output_dir, metric_name, round_num, sortby=\"Model_Strategy\"):\n",
    "    \"\"\"\n",
    "    Creates a boxplot for the given metric from the pivot CSV.\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Path to pivot CSV file.\n",
    "        output_dir (str): Directory to save the plot.\n",
    "        metric_name (str): Column name to plot on Y-axis.\n",
    "        round_num (int): Round number for file naming.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the pivot CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    if metric_name not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric_name}' not found in the CSV columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Sort X-axis by Model_Strategy for clean look\n",
    "    df = df.sort_values(by=sortby)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.boxplot(df[metric_name], vert=True)\n",
    "    plt.xticks([1], [metric_name])\n",
    "    plt.title(f\"{metric_name} Boxplot for Round {round_num}\")\n",
    "    plt.ylabel(metric_name)\n",
    "    \n",
    "    # Save plot\n",
    "    plot_name = f\"{metric_name}_round{round_num}_sorting_strategy{sortby}_pivot_boxplot.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_name)\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[OK] Boxplot saved: {plot_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
